{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29448727-6261-41d7-ba76-a9afa37d52be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved to: /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/de_en/self_correction_isolated_training_with_clean_analysis.tsv\n",
      "Total rows: 1472\n",
      "Clean rows with analysis: 736\n",
      "Error rows: 736\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "INPUT_TSV = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/de_en/self_correction_isolated_training_merged.tsv\"\n",
    "OUTPUT_TSV = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/de_en/self_correction_isolated_training_with_clean_analysis.tsv\"\n",
    "\n",
    "df = pd.read_csv(INPUT_TSV, sep=\"\\t\", dtype=str, keep_default_na=False)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "def generate_clean_analysis(row):\n",
    "    translation = row[\"target_en\"].strip()\n",
    "    \n",
    "    analysis = (\n",
    "        f'The translation is \"{translation}\"\\n'\n",
    "        f'By double checking, I see the translation is correct\\n'\n",
    "        f'The correct translation is \"{translation}\"'\n",
    "    )\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# apply to clean_translation rows \n",
    "for idx, row in df.iterrows():\n",
    "    if row[\"data_type\"].lower() == \"clean_translation\":\n",
    "        if pd.isna(row.get(\"analysis\", \"\")) or row.get(\"analysis\", \"\").strip() == \"\":\n",
    "            df.at[idx, \"analysis\"] = generate_clean_analysis(row)\n",
    "\n",
    "df.to_csv(OUTPUT_TSV, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Updated dataset saved to: {OUTPUT_TSV}\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Clean rows with analysis: {len(df[df['data_type'] == 'clean_translation'])}\")\n",
    "print(f\"Error rows: {len(df[df['data_type'] == 'error_correction'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d8b618b-41cb-4676-88c8-8f8c7f3bbed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error_correction rows: 736\n",
      "Rows with 'The model translation is': 736\n",
      "Rows with 'The correct translation': 736\n",
      "Rows with both (expected format): 736\n",
      "Rows NOT matching expected format: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "INPUT_TSV = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/de_en/self_correction_isolated_training_with_clean_analysis.tsv\"\n",
    "\n",
    "df = pd.read_csv(INPUT_TSV, sep=\"\\t\", dtype=str, keep_default_na=False)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "error_df = df[df[\"data_type\"].str.lower() == \"error_correction\"].copy()\n",
    "\n",
    "has_model_part = error_df[\"analysis\"].str.contains(r\"The model translation is\", case=False, na=False)\n",
    "has_correct_part = error_df[\"analysis\"].str.contains(r\"The correct translation\", case=False, na=False)\n",
    "\n",
    "error_df[\"has_model_translation\"] = has_model_part\n",
    "error_df[\"has_correct_translation\"] = has_correct_part\n",
    "error_df[\"has_expected_format\"] = has_model_part & has_correct_part\n",
    "\n",
    "total = len(error_df)\n",
    "with_model = has_model_part.sum()\n",
    "with_correct = has_correct_part.sum()\n",
    "fully_formatted = error_df[\"has_expected_format\"].sum()\n",
    "not_formatted = total - fully_formatted\n",
    "\n",
    "print(f\"Total error_correction rows: {total}\")\n",
    "print(f\"Rows with 'The model translation is': {with_model}\")\n",
    "print(f\"Rows with 'The correct translation': {with_correct}\")\n",
    "print(f\"Rows with both (expected format): {fully_formatted}\")\n",
    "print(f\"Rows NOT matching expected format: {not_formatted}\")\n",
    "\n",
    "if not_formatted > 0:\n",
    "    print(\"\\n Rows not following expected format:\")\n",
    "    display(error_df.loc[~error_df[\"has_expected_format\"], [\"source_de\", \"predicted_en\", \"target_en\", \"analysis\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2ff6dda-5432-4791-830c-d319fab63d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error_correction rows: 736\n",
      "Rows with 'The model translation is': 736\n",
      "Rows with 'The correct translation': 736\n",
      "Rows modified (had paragraph-y analysis): 736\n",
      "Saved reflowed file to: /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/de_en/self_correction_isolated_training_with_clean_analysis_formatted.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "INPUT_TSV = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/de_en/self_correction_isolated_training_with_clean_analysis.tsv\"\n",
    "OUTPUT_TSV = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/de_en/self_correction_isolated_training_with_clean_analysis_formatted.tsv\"\n",
    "\n",
    "df = pd.read_csv(INPUT_TSV, sep=\"\\t\", dtype=str, keep_default_na=False)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "mask_err = df[\"data_type\"].str.lower() == \"error_correction\"\n",
    "err = df.loc[mask_err].copy()\n",
    "\n",
    "has_model = err[\"analysis\"].str.contains(r\"The model translation is\", case=False, na=False)\n",
    "has_correct = err[\"analysis\"].str.contains(r\"The correct translation\", case=False, na=False)\n",
    "print(f\"Total error_correction rows: {len(err)}\")\n",
    "print(f\"Rows with 'The model translation is': {has_model.sum()}\")\n",
    "print(f\"Rows with 'The correct translation': {has_correct.sum()}\")\n",
    "\n",
    "def reflow_analysis(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    original = text\n",
    "\n",
    "    text = re.sub(\n",
    "        r'(The model translation is.*?\"\\.?)\\s+(?=[A-Z])',\n",
    "        r'\\1\\n',\n",
    "        text,\n",
    "        flags=re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "\n",
    "    text = re.sub(\n",
    "        r'(?<!\\n)\\s*(The correct translation\\b)',\n",
    "        r'\\n\\1',\n",
    "        text,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    text = re.sub(r'\\n{2,}', '\\n', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "reflowed = err[\"analysis\"].apply(reflow_analysis)\n",
    "\n",
    "changed_mask = (reflowed != err[\"analysis\"])\n",
    "print(f\"Rows modified (had paragraph-y analysis): {changed_mask.sum()}\")\n",
    "\n",
    "df.loc[mask_err, \"analysis\"] = reflowed\n",
    "df.to_csv(OUTPUT_TSV, sep=\"\\t\", index=False)\n",
    "print(f\"Saved reflowed file to: {OUTPUT_TSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e25b54e5-1e13-4a7f-a72a-93c9293123d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Row 1 ---\n",
      "The model translation is \"On Wednesday, the mileage was cut by another 25%.\" The German \"noch einmal auf 25 Prozent der Flugstrecke gekürzt\" should be \"slashed the mileage award to 25 percent of the miles of the trip\" not \"cut by another 25%\" - this is about reducing TO 25%, not BY 25%. The word \"Meilen\" should be \"mileage award\" not just \"mileage\" - this is about reward points, not distance measurement. The phrase \"der Flugstrecke\" should be \"of the miles of the trip\" not omitted entirely. The grammatical structure \"cut by\" versus \"slashed...to\" changes the mathematical meaning significantly. The correct translation should be \"On Wednesday it slashed the mileage award to 25 percent of the miles of the trip.\"\n",
      "-------------------\n",
      "\n",
      "--- Row 2 ---\n",
      "The model translation is \"Despite the months of debate about the photos of Özil with the Turkish President, Mr. Özil's resignation is to be regretted.\" The phrase \"ist zu bedauern\" means \"is to be regretted\" which the model got correct, but this contradicts the target which suggests it should be about the resignation being unexpected rather than regrettable. The model added \"Mr.\" unnecessarily. The correct translation should be \"In spite of\" rather than \"In spite of the debate going on for months about the photos of Özil with the Turkish President Recep Tayyip Erdogan, he regrets the return of the 92-match national player Özil.\"\n",
      "-------------------\n",
      "\n",
      "--- Row 3 ---\n",
      "The model translation is \"A government which hides the national debt, elections and a new government which is on the same wavelength.\" The German \"Staatsverschuldung\" was translated as \"national debt\" when it should be \"public deficit\" in this political context. The idiomatic phrase \"am gleichen Strang zieht\" was translated as \"on the same wavelength\" but should be \"pulls up the rug\", which conveys a different meaning about revealing or exposing something rather than agreement. The model missed the political metaphor about uncovering hidden information. The correct translation should be \"A Government which hides the public deficit, elections and a new Government that pulls up the rug.\"\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(err[\"analysis\"].head(3), 1):\n",
    "    print(f\"\\n--- Row {i} ---\\n{text}\\n-------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71fe020b-7102-4115-93b1-c3e3281c7a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1472 rows\n",
      "Columns: ['source_de', 'target_en', 'predicted_en', 'error_type', 'analysis', 'data_type']\n",
      "Fixed 1472 rows by adding |||END|||\n",
      "Verification: 1472/1472 rows now end with |||END|||\n",
      "\n",
      "Sample fixed analyses:\n",
      "\n",
      "Row 0 - Last 80 chars:\n",
      "...y it slashed the mileage award to 25 percent of the miles of the trip.\"|||END|||\n",
      "\n",
      "Row 1 - Last 80 chars:\n",
      "...and shame report, which I fear will alienate many of the stakeholders.\"|||END|||\n",
      "\n",
      "Row 2 - Last 80 chars:\n",
      "...p Erdogan, he regrets the return of the 92-match national player Özil.\"|||END|||\n",
      "\n",
      "Saved fixed data to: /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/de_en/self_correction_isolated_training_fixed.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/de_en/self_correction_isolated_training_with_clean_analysis_formatted.tsv\"\n",
    "output_file = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/de_en/self_correction_isolated_training_fixed.tsv\"\n",
    "\n",
    "END_SENT = \"|||END|||\"\n",
    "\n",
    "df = pd.read_csv(input_file, sep=\"\\t\", dtype=str, keep_default_na=False)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "fixed_count = 0\n",
    "for idx in range(len(df)):\n",
    "    analysis = df.at[idx, \"analysis\"].rstrip()\n",
    "    if analysis and not analysis.endswith(END_SENT):\n",
    "        df.at[idx, \"analysis\"] = f\"{analysis}{END_SENT}\"\n",
    "        fixed_count += 1\n",
    "\n",
    "print(f\"Fixed {fixed_count} rows by adding {END_SENT}\")\n",
    "\n",
    "count_with_end = df[\"analysis\"].str.endswith(END_SENT).sum()\n",
    "print(f\"Verification: {count_with_end}/{len(df)} rows now end with {END_SENT}\")\n",
    "\n",
    "print(\"\\nSample fixed analyses:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nRow {i} - Last 80 chars:\")\n",
    "    print(f\"...{df.iloc[i]['analysis'][-80:]}\")\n",
    "\n",
    "df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "print(f\"\\nSaved fixed data to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c724316-8af0-4c6e-b4de-a474972168e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b1f871-136b-4bf0-9ccb-8d14827c23d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86a9b129-5a6c-41cb-80b8-4a561d890036",
   "metadata": {},
   "outputs": [],
   "source": [
    "###chinese to english "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4318cdd8-f5c6-43b9-a257-96a52804ac77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved to: /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/zh_en/chinese_english_analysis_with_clean_analysis.tsv\n",
      "Total rows: 1600\n",
      "Clean rows with analysis: 800\n",
      "Error rows: 800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "INPUT_TSV = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/zh_en/chinese_english_analysis_mixed.tsv\"\n",
    "OUTPUT_TSV = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/zh_en/chinese_english_analysis_with_clean_analysis.tsv\"\n",
    "\n",
    "df = pd.read_csv(INPUT_TSV, sep=\"\\t\", dtype=str, keep_default_na=False)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "def generate_clean_analysis(row):\n",
    "    translation = row[\"target_en\"].strip()\n",
    "    \n",
    "    analysis = (\n",
    "        f'The model translation is \"{translation}\"\\n'\n",
    "        f'By double checking, I see the translation is correct.\\n'\n",
    "        f'The correct translation is \"{translation}\"'\n",
    "    )\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if row[\"data_type\"].lower() == \"clean_translation\":\n",
    "        if pd.isna(row.get(\"analysis\", \"\")) or row.get(\"analysis\", \"\").strip() == \"\":\n",
    "            df.at[idx, \"analysis\"] = generate_clean_analysis(row)\n",
    "\n",
    "df.to_csv(OUTPUT_TSV, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Updated dataset saved to: {OUTPUT_TSV}\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Clean rows with analysis: {len(df[df['data_type'] == 'clean_translation'])}\")\n",
    "print(f\"Error rows: {len(df[df['data_type'] == 'error_correction'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79e7d6e5-c630-46a5-8f35-16a55a2089e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error_correction rows: 800\n",
      "Rows with 'The model translation is': 800\n",
      "Rows with 'The correct translation': 799\n",
      "Rows with both (expected format): 799\n",
      "Rows NOT matching expected format: 1\n",
      "\n",
      " Rows not following expected format:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_zh</th>\n",
       "      <th>predicted_en</th>\n",
       "      <th>target_en</th>\n",
       "      <th>analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>类似的药方 — — 以及包括大幅通胀的药方 — — 颇有市场，以往内对付经济停滞的常规手段已...</td>\n",
       "      <td>Such prescriptions – and others that include s...</td>\n",
       "      <td>Prescriptions like these – as with those for a...</td>\n",
       "      <td>The model translation is \"Such prescriptions –...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           source_zh  \\\n",
       "7  类似的药方 — — 以及包括大幅通胀的药方 — — 颇有市场，以往内对付经济停滞的常规手段已...   \n",
       "\n",
       "                                        predicted_en  \\\n",
       "7  Such prescriptions – and others that include s...   \n",
       "\n",
       "                                           target_en  \\\n",
       "7  Prescriptions like these – as with those for a...   \n",
       "\n",
       "                                            analysis  \n",
       "7  The model translation is \"Such prescriptions –...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "INPUT_TSV = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/zh_en/chinese_english_analysis_with_clean_analysis.tsv\"\n",
    "\n",
    "df = pd.read_csv(INPUT_TSV, sep=\"\\t\", dtype=str, keep_default_na=False)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "error_df = df[df[\"data_type\"].str.lower() == \"error_correction\"].copy()\n",
    "\n",
    "has_model_part = error_df[\"analysis\"].str.contains(r\"The model translation is\", case=False, na=False)\n",
    "has_correct_part = error_df[\"analysis\"].str.contains(r\"The correct translation\", case=False, na=False)\n",
    "\n",
    "error_df[\"has_model_translation\"] = has_model_part\n",
    "error_df[\"has_correct_translation\"] = has_correct_part\n",
    "error_df[\"has_expected_format\"] = has_model_part & has_correct_part\n",
    "\n",
    "total = len(error_df)\n",
    "with_model = has_model_part.sum()\n",
    "with_correct = has_correct_part.sum()\n",
    "fully_formatted = error_df[\"has_expected_format\"].sum()\n",
    "not_formatted = total - fully_formatted\n",
    "\n",
    "print(f\"Total error_correction rows: {total}\")\n",
    "print(f\"Rows with 'The model translation is': {with_model}\")\n",
    "print(f\"Rows with 'The correct translation': {with_correct}\")\n",
    "print(f\"Rows with both (expected format): {fully_formatted}\")\n",
    "print(f\"Rows NOT matching expected format: {not_formatted}\")\n",
    "\n",
    "if not_formatted > 0:\n",
    "    print(\"\\n Rows not following expected format:\")\n",
    "    display(error_df.loc[~error_df[\"has_expected_format\"], [\"source_zh\", \"predicted_en\", \"target_en\", \"analysis\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "179ae625-4ec1-4163-a3a2-6eac27f6f507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [source_zh, target_en, predicted_en, error type - single, analysis, data_type]\n",
      "Index: []\n",
      "\n",
      "No exact match found — trying partial search...\n",
      "                                           source_zh  \\\n",
      "7  类似的药方 — — 以及包括大幅通胀的药方 — — 颇有市场，以往内对付经济停滞的常规手段已...   \n",
      "\n",
      "                                           target_en  \\\n",
      "7  Prescriptions like these – as with those for a...   \n",
      "\n",
      "                                        predicted_en error type - single  \\\n",
      "7  Such prescriptions – and others that include s...       Lexical Error   \n",
      "\n",
      "                                            analysis         data_type  \n",
      "7  The model translation is \"Such prescriptions –...  error_correction  \n",
      "\n",
      "Row index: [7]\n",
      "\n",
      "Selected columns:\n",
      "                                              source_zh                                                                                                                                                              target_en                                                                                                                                                                                         predicted_en error type - single                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           analysis\n",
      "类似的药方 — — 以及包括大幅通胀的药方 — — 颇有市场，以往内对付经济停滞的常规手段已经试过并宣告失败。 Prescriptions like these – as with those for a jolt of inflation – have gained ground because the obvious solutions to economic stagnation have been tried and failed. Such prescriptions – and others that include substantial inflation – are in vogue, and conventional remedies for economic stagnation that have been tried and found wanting are no longer an option.       Lexical Error The model translation is \"Such prescriptions – and others that include substantial inflation – are in vogue, and conventional remedies for economic stagnation that have been tried and found wanting are no longer an option.\" The model changes \"prescriptions like these\" to \"such prescriptions – and others that include substantial inflation,\" making the inflation reference sound like a separate category when it should be included in \"like these.\" The phrase \"no longer an option\" is also an addition. The original says \"the obvious solutions...have been tried and failed,\" not that they're no longer options. The model changes the meaning from \"failed\" to \"no longer an option,\" which is subtly different.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "INPUT_TSV = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/zh_en/chinese_english_analysis_with_clean_analysis.tsv\"\n",
    "forcheckingdf = pd.read_csv(INPUT_TSV, sep='\\t')\n",
    "\n",
    "search_text = \"Prescriptions like these – as with those for a jolt of inflation – have gained ground because the obvious solutions to economic stagnation have been tried and failed.policy makers, if not more so.\"\n",
    "\n",
    "match = forcheckingdf[forcheckingdf['target_en'].str.strip() == search_text]\n",
    "\n",
    "print(match)\n",
    "\n",
    "if match.empty:\n",
    "    print(\"\\nNo exact match found — trying partial search...\")\n",
    "    match = forcheckingdf[forcheckingdf['target_en'].str.contains(\"Prescriptions like these\", case=False, na=False)]\n",
    "    print(match)\n",
    "\n",
    "if not match.empty:\n",
    "    print(\"\\nRow index:\", match.index.tolist())\n",
    "    print(\"\\nSelected columns:\")\n",
    "    print(match[['source_zh', 'target_en', 'predicted_en', 'error type - single', 'analysis']].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d11a86a9-0036-4cf0-88a0-49710c2c2370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated analysis for row 7:\n",
      "The model translation is \"Such prescriptions – and others that include substantial inflation – are in vogue, and conventional remedies for economic stagnation that have been tried and found wanting are no longer an option.\" The model changes \"prescriptions like these\" to \"such prescriptions – and others that include substantial inflation,\" making the inflation reference sound like a separate category when it should be included in \"like these.\" The phrase \"no longer an option\" is also an addition. The correct translation is \"Prescriptions like these – as with those for a jolt of inflation – have gained ground because the obvious solutions to economic stagnation have been tried and failed.\"\n",
      "\n",
      "Change saved successfully to: /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/zh_en/chinese_english_analysis_with_clean_analysis.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "INPUT_TSV = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/zh_en/chinese_english_analysis_with_clean_analysis.tsv\"\n",
    "forcheckingdf = pd.read_csv(INPUT_TSV, sep='\\t')\n",
    "\n",
    "new_analysis = '''The model translation is \"Such prescriptions – and others that include substantial inflation – are in vogue, and conventional remedies for economic stagnation that have been tried and found wanting are no longer an option.\" The model changes \"prescriptions like these\" to \"such prescriptions – and others that include substantial inflation,\" making the inflation reference sound like a separate category when it should be included in \"like these.\" The phrase \"no longer an option\" is also an addition. The correct translation is \"Prescriptions like these – as with those for a jolt of inflation – have gained ground because the obvious solutions to economic stagnation have been tried and failed.\"'''\n",
    "\n",
    "forcheckingdf.loc[7, 'analysis'] = new_analysis\n",
    "\n",
    "print(\"Updated analysis for row 7:\")\n",
    "print(forcheckingdf.loc[7, 'analysis'])\n",
    "\n",
    "forcheckingdf.to_csv(INPUT_TSV, sep='\\t', index=False)\n",
    "print(\"\\nChange saved successfully to:\", INPUT_TSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb6ac5d9-a5f5-47da-a35a-bd5cbc88362f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error_correction rows: 800\n",
      "Rows with 'The model translation is': 800\n",
      "Rows with 'The correct translation': 800\n",
      "Rows modified (had paragraph-y analysis): 800\n",
      "Saved reflowed file to: /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/zh_en/chinese_english_analysis_with_clean_analysis_formatting.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "INPUT_TSV = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/zh_en/chinese_english_analysis_with_clean_analysis.tsv\"\n",
    "OUTPUT_TSV = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/zh_en/chinese_english_analysis_with_clean_analysis_formatting.tsv\"\n",
    "\n",
    "df = pd.read_csv(INPUT_TSV, sep=\"\\t\", dtype=str, keep_default_na=False)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "mask_err = df[\"data_type\"].str.lower() == \"error_correction\"\n",
    "err = df.loc[mask_err].copy()\n",
    "\n",
    "has_model = err[\"analysis\"].str.contains(r\"The model translation is\", case=False, na=False)\n",
    "has_correct = err[\"analysis\"].str.contains(r\"The correct translation\", case=False, na=False)\n",
    "print(f\"Total error_correction rows: {len(err)}\")\n",
    "print(f\"Rows with 'The model translation is': {has_model.sum()}\")\n",
    "print(f\"Rows with 'The correct translation': {has_correct.sum()}\")\n",
    "\n",
    "def reflow_analysis(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    original = text\n",
    "\n",
    "    text = re.sub(\n",
    "        r'(The model translation is.*?\"\\.?)\\s+(?=[A-Z])',\n",
    "        r'\\1\\n',\n",
    "        text,\n",
    "        flags=re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "\n",
    "    # line break \n",
    "    text = re.sub(\n",
    "        r'(?<!\\n)\\s*(The correct translation\\b)',\n",
    "        r'\\n\\1',\n",
    "        text,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    #  trim extra blank lines \n",
    "    text = re.sub(r'\\n{2,}', '\\n', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "reflowed = err[\"analysis\"].apply(reflow_analysis)\n",
    "\n",
    "changed_mask = (reflowed != err[\"analysis\"])\n",
    "print(f\"Rows modified (had paragraph-y analysis): {changed_mask.sum()}\")\n",
    "\n",
    "df.loc[mask_err, \"analysis\"] = reflowed\n",
    "df.to_csv(OUTPUT_TSV, sep=\"\\t\", index=False)\n",
    "print(f\"Saved reflowed file to: {OUTPUT_TSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a440f4b-d3a5-4114-bbac-4b36699d6e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Row 1 ---\n",
      "The model translation is \"If you play the Russian roulette with just one or two bullets, your chances of survival are certainly better than if you play with six, but the stakes are so high – or the value of what you are betting is so low – that it is not a smart bet.\" The model adds a comparison to playing with six bullets that is not in the original text. The original statement is about how even with good survival odds, the stakes make it unwise. The model also changes \"you are more likely to survive than not\" to \"your chances of survival are certainly better than if you play with six,\" which introduces an unnecessary comparison. The phrase \"smart bet\" is less formal than the original's \"wise gamble.\" The model also loses the emphasis on how extraordinarily high the stakes would need to be or how low one's self-valuation must be. The correct translation should be \"If you play Russian roulette with one or two bullets in the barrel, you are more likely to survive than not, but the stakes would need to be astonishingly high – or the value you place on your life inordinately low – for this to seem a wise gamble.\"\n",
      "-------------------\n",
      "\n",
      "--- Row 2 ---\n",
      "The model translation is \"And it is much more popular than the various schemes to increase Greece's debt burden, which was already excessive, in one way or another.\" The model changes \"foisting more debt onto a country\" to \"increase Greece's debt burden,\" which is more abstract and loses the critical sense of forcing or imposing debt. The phrase \"in one way or another\" at the end is awkwardly placed and changes the meaning - the source text's \"under different guises\" refers to how the schemes disguise their true nature, not to varied methods of implementation. The correct translation should be \"This is a welcome contrast to the options considered so far, all of which involved – under different guises – foisting more debt onto a country that has too much of it already.\"\n",
      "-------------------\n",
      "\n",
      "--- Row 3 ---\n",
      "The model translation is \"Before the poor performance of stocks from 19₉8 to 20₀8, there were two periods of relatively good performance, from ₁97₈ to 1₉8₈, and from １98₈ to 1₉98, and it seemed likely that the trend would continue for another decade.\" The model has strange character encoding issues with some numbers appearing in different fonts (₉, ₀, ₁, １). The structure is also awkward with \"there were two periods\" being less natural than \"periods like 1998-2008... are preceded by periods.\" The model also adds \"for another decade\" when the source just says \"are in all likelihood followed by similar periods,\" losing the cyclic pattern implication. The correct translation should be \"Periods like 1998-2008, in which stocks do relatively badly, are preceded by periods – like 1978-1988 and 1988-1998 – in which they do relatively well, and are in all likelihood followed by similar periods.\"\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(err[\"analysis\"].head(3), 1):\n",
    "    print(f\"\\n--- Row {i} ---\\n{text}\\n-------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ca627fc-0abc-469d-b0f2-ba121b48eb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Structure check:\n",
      "Total 'error_correction' rows: 800\n",
      "Rows containing BOTH sections ('The model translation is' ... 'The correct translation'): 800\n",
      "Rows missing one or both sections: 0\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"The model translation is.*The correct translation\"\n",
    "\n",
    "matches = err[\"analysis\"].str.contains(pattern, flags=re.IGNORECASE | re.DOTALL, na=False)\n",
    "\n",
    "total_err = len(err)\n",
    "matching_rows = matches.sum()\n",
    "missing_rows = total_err - matching_rows\n",
    "\n",
    "print(f\"\\nStructure check:\")\n",
    "print(f\"Total 'error_correction' rows: {total_err}\")\n",
    "print(f\"Rows containing BOTH sections ('The model translation is' ... 'The correct translation'): {matching_rows}\")\n",
    "print(f\"Rows missing one or both sections: {missing_rows}\")\n",
    "\n",
    "if missing_rows > 0:\n",
    "    print(\"\\n Rows missing structure:\")\n",
    "    display(err.loc[~matches, [\"source_zh\", \"target_en\", \"analysis\"]].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3138e1bf-1ced-49c0-af0b-78f478a9a71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Structure check:\n",
      "Total 'error_correction' rows: 800\n",
      "Rows with both 'The model translation is' and 'The correct translation': 800\n",
      "Rows missing one or both sections: 0\n",
      "\n",
      " Rows reformatted (added clean paragraph breaks): 800\n",
      "\n",
      "Formatted file saved to:\n",
      "/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/zh_en/chinese_english_analysis_with_clean_analysis_formatted.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "INPUT_TSV = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/zh_en/chinese_english_analysis_with_clean_analysis.tsv\"\n",
    "OUTPUT_TSV = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/zh_en/chinese_english_analysis_with_clean_analysis_formatted.tsv\"\n",
    "\n",
    "df = pd.read_csv(INPUT_TSV, sep=\"\\t\", dtype=str, keep_default_na=False)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "mask_err = df[\"data_type\"].str.lower() == \"error_correction\"\n",
    "err = df.loc[mask_err].copy()\n",
    "\n",
    "pattern = r\"The model translation is.*The correct translation\"\n",
    "matches = err[\"analysis\"].str.contains(pattern, flags=re.IGNORECASE | re.DOTALL, na=False)\n",
    "\n",
    "print(f\"\\nStructure check:\")\n",
    "print(f\"Total 'error_correction' rows: {len(err)}\")\n",
    "print(f\"Rows with both 'The model translation is' and 'The correct translation': {matches.sum()}\")\n",
    "print(f\"Rows missing one or both sections: {len(err) - matches.sum()}\")\n",
    "\n",
    "def reflow_analysis(text: str) -> str:\n",
    "    \"\"\"Add line breaks for readability between main analysis sections.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    text = re.sub(\n",
    "        r'(The model translation is.*?\"\\.?)\\s+(?=[A-Z])',\n",
    "        r'\\1\\n',\n",
    "        text,\n",
    "        flags=re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "\n",
    "    text = re.sub(\n",
    "        r'(?<!\\n)\\s*(The correct translation\\b)',\n",
    "        r'\\n\\1',\n",
    "        text,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    text = re.sub(r'\\n{2,}', '\\n', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "reflowed = err[\"analysis\"].where(~matches, err[\"analysis\"].apply(reflow_analysis))\n",
    "\n",
    "changed_mask = (reflowed != err[\"analysis\"])\n",
    "print(f\"\\n Rows reformatted (added clean paragraph breaks): {changed_mask.sum()}\")\n",
    "\n",
    "df.loc[mask_err, \"analysis\"] = reflowed\n",
    "df.to_csv(OUTPUT_TSV, sep=\"\\t\", index=False)\n",
    "print(f\"\\nFormatted file saved to:\\n{OUTPUT_TSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aef78f-c86c-4a51-ab6c-623f8cc716d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, text in enumerate(df.loc[mask_err, \"analysis\"].head(5), 1):\n",
    "    print(f\"\\n--- error_correction Row {i} ---\\n{text}\\n-------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6328a6e-5d57-42c8-8d3d-b21900f15098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1600 rows\n",
      "Columns: ['source_zh', 'target_en', 'predicted_en', 'error type - single', 'analysis', 'data_type']\n",
      "Fixed 1600 rows by adding |||END|||\n",
      "Verification: 1600/1600 rows now end with |||END|||\n",
      "\n",
      "Sample fixed analyses:\n",
      "\n",
      "Row 0 - Last 80 chars:\n",
      "... place on your life inordinately low – for this to seem a wise gamble.\"|||END|||\n",
      "\n",
      "Row 1 - Last 80 chars:\n",
      "...s – foisting more debt onto a country that has too much of it already.\"|||END|||\n",
      "\n",
      "Row 2 - Last 80 chars:\n",
      "...elatively well, and are in all likelihood followed by similar periods.\"|||END|||\n",
      "\n",
      "Saved fixed data to: /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/zh_en/chinese_english_analysis_with_clean_analysis_fixed.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/zh_en/chinese_english_analysis_with_clean_analysis_formatted.tsv\"\n",
    "output_file = \"/sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/data/isolated_clean/zh_en/chinese_english_analysis_with_clean_analysis_fixed.tsv\"\n",
    "\n",
    "END_SENT = \"|||END|||\"\n",
    "\n",
    "df = pd.read_csv(input_file, sep=\"\\t\", dtype=str, keep_default_na=False)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "fixed_count = 0\n",
    "for idx in range(len(df)):\n",
    "    analysis = df.at[idx, \"analysis\"].rstrip()\n",
    "    if analysis and not analysis.endswith(END_SENT):\n",
    "        df.at[idx, \"analysis\"] = f\"{analysis}{END_SENT}\"\n",
    "        fixed_count += 1\n",
    "\n",
    "print(f\"Fixed {fixed_count} rows by adding {END_SENT}\")\n",
    "\n",
    "\n",
    "count_with_end = df[\"analysis\"].str.endswith(END_SENT).sum()\n",
    "print(f\"Verification: {count_with_end}/{len(df)} rows now end with {END_SENT}\")\n",
    "\n",
    "print(\"\\nSample fixed analyses:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nRow {i} - Last 80 chars:\")\n",
    "    print(f\"...{df.iloc[i]['analysis'][-80:]}\")\n",
    "\n",
    "df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "print(f\"\\nSaved fixed data to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d767c-f128-48a5-9c4e-fb3ca17c2459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
