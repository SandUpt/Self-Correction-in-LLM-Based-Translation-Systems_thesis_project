{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c2c3e50-9243-416c-9cf1-a30ac99b3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "LANG_PAIR = \"zh_en\"  # \"de_en\", zh_en\n",
    "\n",
    "INPUT_PATHS = {\n",
    "    \"zh_en\": \"../../data/isolated_clean/zh_en/chinese_english_analysis_with_clean_analysis_fixed.tsv\",\n",
    "    \"de_en\": \"../../data/isolated_clean/de_en/self_correction_isolated_training_with_clean_analysis.tsv\"\n",
    "}\n",
    "\n",
    "OUTPUT_DIR = {\n",
    "    \"zh_en\": \"../../data/processed/zh_en/self_correction_zh_en\",\n",
    "    \"de_en\": \"../../data/processed/de_en/self_correction_de_en\"\n",
    "}\n",
    "\n",
    "SOURCE_COL = {\"zh_en\": \"source_zh\", \"de_en\": \"source_de\"}\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fab93714-bf9f-4cc9-b22b-2f995e1d4ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_analysis(text, data_type):\n",
    "    if not text or not text.strip():\n",
    "        if data_type == \"clean_translation\":\n",
    "            return \"the translation accurately captures the meaning\"\n",
    "        return \"\"\n",
    "    \n",
    "    text = text.replace(\"|||END|||\", \"\").strip()\n",
    "    \n",
    "    if data_type == \"clean_translation\":\n",
    "        return \"the translation accurately captures the meaning\"\n",
    "    \n",
    "    if \"The model translation is\" in text:\n",
    "        parts = text.split('.\"')\n",
    "        if len(parts) > 1:\n",
    "            text = parts[1].strip()\n",
    "        else:\n",
    "            sentences = text.split(\".\")\n",
    "            for i, sent in enumerate(sentences):\n",
    "                if \"model translation\" not in sent.lower():\n",
    "                    text = \". \".join(sentences[i:])\n",
    "                    break\n",
    "    \n",
    "    for pattern in [\"correct translation should be\", \"correct translation is\"]:\n",
    "        if pattern in text.lower():\n",
    "            idx = text.lower().rfind(\"the correct translation\")\n",
    "            if idx != -1:\n",
    "                text = text[:idx].strip()\n",
    "    \n",
    "    return text.strip().rstrip(\".\")\n",
    "\n",
    "\n",
    "def format_example(row, source_col):\n",
    "    source = row[source_col].strip()\n",
    "    target = row[\"target_en\"].strip()\n",
    "    data_type = row[\"data_type\"]\n",
    "    analysis = clean_analysis(row.get(\"analysis\", \"\"), data_type)\n",
    "    \n",
    "    lang_name = \"Chinese\" if \"zh\" in source_col else \"German\"\n",
    "    prompt = f\"Translate the following {lang_name} to English:\\n{source}\"\n",
    "    \n",
    "    initial = row[\"predicted_en\"].strip() if data_type == \"error_correction\" else target\n",
    "    \n",
    "    completion = f\"\"\"Initial translation: {initial}\n",
    "\n",
    "Analysis: {analysis}\n",
    "\n",
    "Corrected translation: {target}\"\"\"\n",
    "    \n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"completion\": completion,\n",
    "        \"data_type\": data_type,\n",
    "        source_col: source,\n",
    "        \"target_en\": target\n",
    "    }\n",
    "\n",
    "\n",
    "def create_70_30_split(df, seed=42):\n",
    "    error_df = df[df[\"data_type\"] == \"error_correction\"].copy()\n",
    "    clean_df = df[df[\"data_type\"] == \"clean_translation\"].copy()\n",
    "    \n",
    "    n_error = len(error_df)\n",
    "    target_clean = int(n_error / 0.7 * 0.3)\n",
    "    \n",
    "    if target_clean > len(clean_df):\n",
    "        clean_sampled = clean_df\n",
    "    else:\n",
    "        clean_sampled = clean_df.sample(n=target_clean, random_state=seed)\n",
    "    \n",
    "    combined = pd.concat([error_df, clean_sampled], ignore_index=True)\n",
    "    return combined.sample(frac=1, random_state=seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09d0301f-e1a3-40d0-a559-d51799153320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1600 examples (error: 800, clean: 800)\n",
      "\n",
      "original format\n",
      "The model translation is \"If you play the Russian roulette with just one or two bullets, your chances of survival are certainly better than if you play with six, but the stakes are so high – or the value of what you are betting is so low – that it is not a smart bet.\"\n",
      "The model adds a comparison to playing with six bullets that is not in the original text. The original statement is about how even \n",
      "\n",
      "new one\n",
      "Initial translation: If you play the Russian roulette with just one or two bullets, your chances of survival are certainly better than if you play with six, but the stakes are so high – or the value of what you are betting is so low – that it is not a smart bet.\n",
      "\n",
      "Analysis: The model adds a comparison to playing with six bullets that is not in the original text. The original statement is about how even with good survival odds, the stakes make it unwise. The model also changes \"you are more likely to survive than not\" to \"your chances of survival are certainly better than if you play with six,\" which introduces an unnecessary comparison. The phrase \"smart bet\" is less formal than the original's \"wise gamble\n",
      "\n",
      "Corrected translation: If you play Russian roulette with one or two bullets in the barrel, you are more likely to survive than not, but the stakes would need to be astonishingly high – or the value you place on your life inordinately low – for this to seem a wise gamble.\n"
     ]
    }
   ],
   "source": [
    "source_col = SOURCE_COL[LANG_PAIR]\n",
    "\n",
    "df = pd.read_csv(INPUT_PATHS[LANG_PAIR], sep=\"\\t\", dtype=str, keep_default_na=False)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "n_error = (df[\"data_type\"] == \"error_correction\").sum()\n",
    "n_clean = (df[\"data_type\"] == \"clean_translation\").sum()\n",
    "print(f\"Loaded {len(df)} examples (error: {n_error}, clean: {n_clean})\")\n",
    "\n",
    "error_ex = df[df[\"data_type\"] == \"error_correction\"].iloc[0]\n",
    "print(\"\\noriginal format\")\n",
    "print(error_ex.get(\"analysis\", \"\")[:400])\n",
    "\n",
    "formatted_ex = format_example(error_ex, source_col)\n",
    "print(\"\\nnew one\")\n",
    "print(formatted_ex[\"completion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06a89f1b-3bcc-456c-a25c-cbe9ecebd1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50-50 Split:\n",
      "  Train: 1400 (error: 700, clean: 700)\n",
      "  Val: 200 (error: 100, clean: 100)\n",
      "\n",
      "70-30 Split:\n",
      "  Train: 1000 (error: 700 [70.0%], clean: 300 [30.0%])\n",
      "  Val: 200 (balanced)\n"
     ]
    }
   ],
   "source": [
    "formatted = [format_example(row, source_col) for _, row in df.iterrows()]\n",
    "formatted_df = pd.DataFrame(formatted)\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    formatted_df, test_size=0.125, random_state=SEED, stratify=formatted_df[\"data_type\"]\n",
    ")\n",
    "\n",
    "train_error = (train_df[\"data_type\"] == \"error_correction\").sum()\n",
    "train_clean = (train_df[\"data_type\"] == \"clean_translation\").sum()\n",
    "val_error = (val_df[\"data_type\"] == \"error_correction\").sum()\n",
    "val_clean = (val_df[\"data_type\"] == \"clean_translation\").sum()\n",
    "\n",
    "print(\"50-50 Split:\")\n",
    "print(f\"  Train: {len(train_df)} (error: {train_error}, clean: {train_clean})\")\n",
    "print(f\"  Val: {len(val_df)} (error: {val_error}, clean: {val_clean})\")\n",
    "\n",
    "train_70_30 = create_70_30_split(train_df, SEED)\n",
    "train_error_70 = (train_70_30[\"data_type\"] == \"error_correction\").sum()\n",
    "train_clean_70 = (train_70_30[\"data_type\"] == \"clean_translation\").sum()\n",
    "\n",
    "print(\"\\n70-30 Split:\")\n",
    "print(f\"  Train: {len(train_70_30)} (error: {train_error_70} [{100*train_error_70/len(train_70_30):.1f}%], clean: {train_clean_70} [{100*train_clean_70/len(train_70_30):.1f}%])\")\n",
    "print(f\"  Val: {len(val_df)} (balanced)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a54c03dc-f1bf-445c-9f4d-316a8cc3ca65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50-50 to ../../data/processed/zh_en/self_correction_zh_en\n",
      "Saved 70-30 to ../../data/processed/zh_en/self_correction_zh_en_70-30\n"
     ]
    }
   ],
   "source": [
    "output_dir = Path(OUTPUT_DIR[LANG_PAIR])\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_df.to_csv(output_dir / \"train.tsv\", sep=\"\\t\", index=False)\n",
    "val_df.to_csv(output_dir / \"val.tsv\", sep=\"\\t\", index=False)\n",
    "print(f\"Saved 50-50 to {output_dir}\")\n",
    "\n",
    "output_dir_70_30 = Path(str(output_dir) + \"_70-30\")\n",
    "output_dir_70_30.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_70_30.to_csv(output_dir_70_30 / \"train.tsv\", sep=\"\\t\", index=False)\n",
    "val_df.to_csv(output_dir_70_30 / \"val.tsv\", sep=\"\\t\", index=False)\n",
    "print(f\"Saved 70-30 to {output_dir_70_30}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7535618d-1591-4116-8f2b-8822fcec85b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c048c7d2-6022-45da-8fd2-26433713f482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65984392-30fc-4ab9-9e5f-826dc1d93018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (User + Packages)",
   "language": "python",
   "name": "user-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
