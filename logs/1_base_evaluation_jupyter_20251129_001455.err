`torch_dtype` is deprecated! Use `dtype` instead!
We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|                                                                                   | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██████████████████▊                                                        | 1/4 [00:04<00:12,  4.31s/it]Loading checkpoint shards:  50%|█████████████████████████████████████▌                                     | 2/4 [00:06<00:06,  3.10s/it]Loading checkpoint shards:  75%|████████████████████████████████████████████████████████▎                  | 3/4 [00:07<00:02,  2.13s/it]Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.37s/it]Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.93s/it]
Generating:   0%|                                                                                                 | 0/21 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Generating:   5%|████▏                                                                                    | 1/21 [00:24<08:00, 24.04s/it]Generating:  10%|████████▍                                                                                | 2/21 [00:46<07:21, 23.24s/it]Generating:  14%|████████████▋                                                                            | 3/21 [01:09<06:55, 23.09s/it]Generating:  19%|████████████████▉                                                                        | 4/21 [01:32<06:31, 23.02s/it]Generating:  24%|█████████████████████▏                                                                   | 5/21 [01:55<06:05, 22.87s/it]Generating:  29%|█████████████████████████▍                                                               | 6/21 [02:18<05:46, 23.08s/it]Generating:  33%|█████████████████████████████▋                                                           | 7/21 [02:41<05:23, 23.09s/it]Generating:  38%|█████████████████████████████████▉                                                       | 8/21 [03:04<04:59, 23.06s/it]Generating:  43%|██████████████████████████████████████▏                                                  | 9/21 [03:27<04:35, 22.96s/it]Generating:  48%|█████████████████████████████████████████▉                                              | 10/21 [03:50<04:13, 23.08s/it]Generating:  52%|██████████████████████████████████████████████                                          | 11/21 [04:12<03:47, 22.77s/it]Generating:  57%|██████████████████████████████████████████████████▎                                     | 12/21 [04:35<03:25, 22.85s/it]Generating:  62%|██████████████████████████████████████████████████████▍                                 | 13/21 [04:58<03:02, 22.82s/it]Generating:  67%|██████████████████████████████████████████████████████████▋                             | 14/21 [05:21<02:39, 22.83s/it]Generating:  71%|██████████████████████████████████████████████████████████████▊                         | 15/21 [05:44<02:16, 22.78s/it]Generating:  76%|███████████████████████████████████████████████████████████████████                     | 16/21 [06:06<01:53, 22.77s/it]Generating:  81%|███████████████████████████████████████████████████████████████████████▏                | 17/21 [06:29<01:31, 22.80s/it]Generating:  86%|███████████████████████████████████████████████████████████████████████████▍            | 18/21 [06:51<01:07, 22.55s/it]Generating:  90%|███████████████████████████████████████████████████████████████████████████████▌        | 19/21 [07:15<00:45, 22.95s/it]Generating:  95%|███████████████████████████████████████████████████████████████████████████████████▊    | 20/21 [07:37<00:22, 22.64s/it]Generating: 100%|████████████████████████████████████████████████████████████████████████████████████████| 21/21 [07:58<00:00, 22.04s/it]Generating: 100%|████████████████████████████████████████████████████████████████████████████████████████| 21/21 [07:58<00:00, 22.77s/it]
Fetching 5 files:   0%|                                                                                            | 0/5 [00:00<?, ?it/s]Fetching 5 files: 100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 4451.61it/s]
Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`
Encoder model frozen.
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 1_base_evaluation.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
