+ echo 'Job ID: 1460063'
+ echo 'Job Name: 8_self_correction_evaluation_2'
+ echo 'Node: gx25'
++ date
+ echo 'Start Time: Tue Dec  2 08:46:52 CET 2025'
++ pwd
+ echo 'Working Directory: /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/sh_files'
+ nvidia-smi
+ cd /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/scripts/
+ export TOKENIZERS_PARALLELISM=false
+ TOKENIZERS_PARALLELISM=false
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ echo 8_self_correction_evaluation_2
+ python3 8_self_correction_evaluation_2.py
`torch_dtype` is deprecated! Use `dtype` instead!
We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:13<00:41, 13.86s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:26<00:26, 13.16s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:40<00:13, 13.44s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:43<00:00,  9.39s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:43<00:00, 10.87s/it]
Generating:   0%|          | 0/157 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Generating:   1%|          | 1/157 [00:30<1:19:42, 30.65s/it]Generating:   1%|▏         | 2/157 [01:20<1:48:21, 41.94s/it]Generating:   2%|▏         | 3/157 [02:10<1:57:08, 45.64s/it]Generating:   3%|▎         | 4/157 [02:36<1:36:26, 37.82s/it]Generating:   3%|▎         | 5/157 [03:07<1:30:07, 35.57s/it]Generating:   4%|▍         | 6/157 [03:35<1:22:53, 32.93s/it]Generating:   4%|▍         | 7/157 [04:26<1:37:14, 38.90s/it]Generating:   5%|▌         | 8/157 [05:17<1:46:03, 42.71s/it]Generating:   6%|▌         | 9/157 [05:48<1:36:11, 39.00s/it]Generating:   6%|▋         | 10/157 [06:20<1:30:21, 36.88s/it]Generating:   7%|▋         | 11/157 [06:59<1:30:58, 37.38s/it]Generating:   8%|▊         | 12/157 [07:50<1:40:21, 41.53s/it]Generating:   8%|▊         | 13/157 [08:24<1:34:20, 39.31s/it]Generating:   9%|▉         | 14/157 [09:14<1:41:30, 42.59s/it]Generating:  10%|▉         | 15/157 [09:49<1:35:04, 40.18s/it]Generating:  10%|█         | 16/157 [10:39<1:41:28, 43.18s/it]Generating:  11%|█         | 17/157 [11:10<1:32:24, 39.60s/it]Generating:  11%|█▏        | 18/157 [12:01<1:39:17, 42.86s/it]Generating:  12%|█▏        | 19/157 [12:52<1:44:42, 45.52s/it]Generating:  13%|█▎        | 20/157 [13:42<1:47:01, 46.87s/it]Generating:  13%|█▎        | 21/157 [14:33<1:48:41, 47.95s/it]Generating:  14%|█▍        | 22/157 [15:23<1:49:41, 48.75s/it]Generating:  15%|█▍        | 23/157 [16:15<1:50:41, 49.56s/it]Generating:  15%|█▌        | 24/157 [17:05<1:50:15, 49.74s/it]Generating:  16%|█▌        | 25/157 [17:33<1:34:51, 43.12s/it]Generating:  17%|█▋        | 26/157 [18:23<1:38:45, 45.23s/it]Generating:  17%|█▋        | 27/157 [19:13<1:41:00, 46.62s/it]Generating:  18%|█▊        | 28/157 [20:02<1:42:03, 47.47s/it]Generating:  18%|█▊        | 29/157 [20:52<1:42:44, 48.16s/it]Generating:  19%|█▉        | 30/157 [21:20<1:29:08, 42.11s/it]Generating:  20%|█▉        | 31/157 [21:49<1:20:12, 38.19s/it]Generating:  20%|██        | 32/157 [22:40<1:27:13, 41.87s/it]Generating:  21%|██        | 33/157 [23:30<1:31:51, 44.45s/it]Generating:  22%|██▏       | 34/157 [23:57<1:20:21, 39.20s/it]Generating:  22%|██▏       | 35/157 [24:48<1:27:11, 42.88s/it]Generating:  23%|██▎       | 36/157 [25:39<1:31:25, 45.33s/it]Generating:  24%|██▎       | 37/157 [26:06<1:19:31, 39.76s/it]Generating:  24%|██▍       | 38/157 [26:56<1:24:33, 42.64s/it]Generating:  25%|██▍       | 39/157 [27:44<1:27:32, 44.51s/it]Generating:  25%|██▌       | 40/157 [28:20<1:21:27, 41.78s/it]Generating:  26%|██▌       | 41/157 [28:55<1:17:06, 39.88s/it]Generating:  27%|██▋       | 42/157 [29:25<1:10:35, 36.83s/it]Generating:  27%|██▋       | 43/157 [30:15<1:17:40, 40.88s/it]Generating:  28%|██▊       | 44/157 [31:02<1:20:28, 42.73s/it]Generating:  29%|██▊       | 45/157 [31:52<1:23:51, 44.92s/it]Generating:  29%|██▉       | 46/157 [32:44<1:26:38, 46.83s/it]Generating:  30%|██▉       | 47/157 [33:33<1:27:23, 47.67s/it]Generating:  31%|███       | 48/157 [34:25<1:28:52, 48.92s/it]Generating:  31%|███       | 49/157 [35:16<1:29:20, 49.63s/it]Generating:  32%|███▏      | 50/157 [36:08<1:29:33, 50.22s/it]Generating:  32%|███▏      | 51/157 [36:59<1:29:06, 50.44s/it]Generating:  33%|███▎      | 52/157 [37:48<1:27:27, 49.98s/it]Generating:  34%|███▍      | 53/157 [38:37<1:26:17, 49.79s/it]Generating:  34%|███▍      | 54/157 [39:28<1:26:01, 50.11s/it]Generating:  35%|███▌      | 55/157 [40:17<1:24:38, 49.79s/it]Generating:  36%|███▌      | 56/157 [41:08<1:24:30, 50.20s/it]Generating:  36%|███▋      | 57/157 [41:58<1:23:39, 50.19s/it]Generating:  37%|███▋      | 58/157 [42:49<1:23:09, 50.39s/it]Generating:  38%|███▊      | 59/157 [43:40<1:22:36, 50.58s/it]Generating:  38%|███▊      | 60/157 [44:29<1:21:01, 50.12s/it]Generating:  39%|███▉      | 61/157 [45:20<1:20:35, 50.37s/it]Generating:  39%|███▉      | 62/157 [46:11<1:19:43, 50.36s/it]Generating:  40%|████      | 63/157 [47:01<1:18:52, 50.35s/it]Generating:  41%|████      | 64/157 [47:52<1:18:09, 50.42s/it]Generating:  41%|████▏     | 65/157 [48:44<1:18:18, 51.07s/it]Generating:  42%|████▏     | 66/157 [49:34<1:16:51, 50.68s/it]Generating:  43%|████▎     | 67/157 [50:03<1:06:18, 44.20s/it]Generating:  43%|████▎     | 68/157 [50:55<1:08:47, 46.38s/it]Generating:  44%|████▍     | 69/157 [51:29<1:02:38, 42.72s/it]Generating:  45%|████▍     | 70/157 [52:19<1:05:14, 45.00s/it]Generating:  45%|████▌     | 71/157 [53:11<1:07:23, 47.02s/it]Generating:  46%|████▌     | 72/157 [54:02<1:08:18, 48.22s/it]Generating:  46%|████▋     | 73/157 [54:53<1:08:36, 49.00s/it]Generating:  47%|████▋     | 74/157 [55:43<1:08:30, 49.52s/it]Generating:  48%|████▊     | 75/157 [56:35<1:08:38, 50.22s/it]Generating:  48%|████▊     | 76/157 [57:26<1:08:00, 50.37s/it]Generating:  49%|████▉     | 77/157 [58:16<1:07:05, 50.31s/it]Generating:  50%|████▉     | 78/157 [59:06<1:06:04, 50.19s/it]Generating:  50%|█████     | 79/157 [59:56<1:05:11, 50.15s/it]Generating:  51%|█████     | 80/157 [1:00:32<59:03, 46.02s/it]Generating:  52%|█████▏    | 81/157 [1:01:22<59:45, 47.18s/it]Generating:  52%|█████▏    | 82/157 [1:01:58<54:39, 43.72s/it]Generating:  53%|█████▎    | 83/157 [1:02:31<50:05, 40.61s/it]Generating:  54%|█████▎    | 84/157 [1:03:02<45:42, 37.56s/it]Generating:  54%|█████▍    | 85/157 [1:03:54<50:15, 41.88s/it]Generating:  55%|█████▍    | 86/157 [1:04:44<52:26, 44.32s/it]Generating:  55%|█████▌    | 87/157 [1:05:35<54:03, 46.33s/it]Generating:  56%|█████▌    | 88/157 [1:06:24<54:13, 47.15s/it]Generating:  57%|█████▋    | 89/157 [1:07:13<54:07, 47.76s/it]Generating:  57%|█████▋    | 90/157 [1:08:04<54:22, 48.69s/it]Generating:  58%|█████▊    | 91/157 [1:08:56<54:39, 49.68s/it]Generating:  59%|█████▊    | 92/157 [1:09:43<52:53, 48.82s/it]Generating:  59%|█████▉    | 93/157 [1:10:31<51:58, 48.73s/it]Generating:  60%|█████▉    | 94/157 [1:11:22<51:59, 49.51s/it]Generating:  61%|██████    | 95/157 [1:12:13<51:22, 49.72s/it]Generating:  61%|██████    | 96/157 [1:13:03<50:51, 50.03s/it]Generating:  62%|██████▏   | 97/157 [1:13:42<46:42, 46.71s/it]Generating:  62%|██████▏   | 98/157 [1:14:34<47:16, 48.08s/it]Generating:  63%|██████▎   | 99/157 [1:15:23<46:46, 48.39s/it]Generating:  64%|██████▎   | 100/157 [1:16:14<46:43, 49.19s/it]Generating:  64%|██████▍   | 101/157 [1:16:43<40:23, 43.27s/it]Generating:  65%|██████▍   | 102/157 [1:17:32<41:08, 44.87s/it]Generating:  66%|██████▌   | 103/157 [1:18:23<42:03, 46.74s/it]Generating:  66%|██████▌   | 104/157 [1:19:14<42:25, 48.04s/it]Generating:  67%|██████▋   | 105/157 [1:20:05<42:21, 48.87s/it]Generating:  68%|██████▊   | 106/157 [1:20:55<41:55, 49.33s/it]Generating:  68%|██████▊   | 107/157 [1:21:46<41:32, 49.84s/it]Generating:  69%|██████▉   | 108/157 [1:22:37<40:53, 50.07s/it]Generating:  69%|██████▉   | 109/157 [1:23:10<35:59, 44.98s/it]Generating:  70%|███████   | 110/157 [1:23:48<33:33, 42.85s/it]Generating:  71%|███████   | 111/157 [1:24:39<34:41, 45.26s/it]Generating:  71%|███████▏  | 112/157 [1:25:07<30:12, 40.27s/it]Generating:  72%|███████▏  | 113/157 [1:25:33<26:14, 35.78s/it]Generating:  73%|███████▎  | 114/157 [1:26:23<28:46, 40.14s/it]Generating:  73%|███████▎  | 115/157 [1:27:14<30:24, 43.45s/it]Generating:  74%|███████▍  | 116/157 [1:28:04<30:59, 45.35s/it]Generating:  75%|███████▍  | 117/157 [1:28:55<31:18, 46.97s/it]Generating:  75%|███████▌  | 118/157 [1:29:46<31:17, 48.15s/it]Generating:  76%|███████▌  | 119/157 [1:30:37<31:06, 49.12s/it]Generating:  76%|███████▋  | 120/157 [1:31:28<30:32, 49.53s/it]Generating:  77%|███████▋  | 121/157 [1:32:18<29:54, 49.85s/it]Generating:  78%|███████▊  | 122/157 [1:33:09<29:15, 50.16s/it]Generating:  78%|███████▊  | 123/157 [1:33:58<28:11, 49.75s/it]Generating:  79%|███████▉  | 124/157 [1:34:47<27:12, 49.46s/it]Generating:  80%|███████▉  | 125/157 [1:35:37<26:32, 49.77s/it]Generating:  80%|████████  | 126/157 [1:36:28<25:50, 50.02s/it]Generating:  81%|████████  | 127/157 [1:37:20<25:17, 50.58s/it]Generating:  82%|████████▏ | 128/157 [1:38:09<24:20, 50.38s/it]Generating:  82%|████████▏ | 129/157 [1:38:58<23:16, 49.87s/it]Generating:  83%|████████▎ | 130/157 [1:39:47<22:21, 49.69s/it]Generating:  83%|████████▎ | 131/157 [1:40:39<21:43, 50.13s/it]Generating:  84%|████████▍ | 132/157 [1:41:09<18:22, 44.09s/it]Generating:  85%|████████▍ | 133/157 [1:41:58<18:13, 45.58s/it]Generating:  85%|████████▌ | 134/157 [1:42:50<18:14, 47.59s/it]Generating:  86%|████████▌ | 135/157 [1:43:40<17:46, 48.46s/it]Generating:  87%|████████▋ | 136/157 [1:44:30<17:03, 48.75s/it]Generating:  87%|████████▋ | 137/157 [1:45:21<16:29, 49.48s/it]Generating:  88%|████████▊ | 138/157 [1:46:12<15:46, 49.82s/it]Generating:  89%|████████▊ | 139/157 [1:47:01<14:52, 49.59s/it]Generating:  89%|████████▉ | 140/157 [1:47:52<14:11, 50.07s/it]Generating:  90%|████████▉ | 141/157 [1:48:32<12:31, 46.94s/it]Generating:  90%|█████████ | 142/157 [1:49:22<12:01, 48.08s/it]Generating:  91%|█████████ | 143/157 [1:50:13<11:23, 48.80s/it]Generating:  92%|█████████▏| 144/157 [1:50:48<09:43, 44.86s/it]Generating:  92%|█████████▏| 145/157 [1:51:38<09:16, 46.42s/it]Generating:  93%|█████████▎| 146/157 [1:52:30<08:46, 47.88s/it]Generating:  94%|█████████▎| 147/157 [1:53:20<08:04, 48.50s/it]Generating:  94%|█████████▍| 148/157 [1:53:48<06:20, 42.32s/it]Generating:  95%|█████████▍| 149/157 [1:54:39<05:59, 44.90s/it]Generating:  96%|█████████▌| 150/157 [1:55:28<05:23, 46.15s/it]Generating:  96%|█████████▌| 151/157 [1:56:19<04:46, 47.73s/it]Generating:  97%|█████████▋| 152/157 [1:57:10<04:04, 48.82s/it]Generating:  97%|█████████▋| 153/157 [1:57:59<03:15, 48.88s/it]Generating:  98%|█████████▊| 154/157 [1:58:51<02:28, 49.56s/it]Generating:  99%|█████████▊| 155/157 [1:59:32<01:34, 47.20s/it]Generating:  99%|█████████▉| 156/157 [2:00:23<00:48, 48.25s/it]Generating: 100%|██████████| 157/157 [2:00:42<00:00, 39.56s/it]Generating: 100%|██████████| 157/157 [2:00:42<00:00, 46.13s/it]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 1142.30it/s]
Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`
Encoder model frozen.
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 8_self_correction_evaluation_2.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 8_self_correction_evaluation_2.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 8_self_correction_evaluation_2.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 8_self_correction_evaluation_2.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
++ date
+ echo 'Done at: Tue Dec  2 10:51:04 CET 2025'
