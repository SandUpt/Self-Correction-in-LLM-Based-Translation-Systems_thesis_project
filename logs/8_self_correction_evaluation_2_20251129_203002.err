`torch_dtype` is deprecated! Use `dtype` instead!
We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|                                                                                               | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|█████████████████████▊                                                                 | 1/4 [00:00<00:02,  1.47it/s]Loading checkpoint shards:  50%|███████████████████████████████████████████▌                                           | 2/4 [00:01<00:01,  1.43it/s]Loading checkpoint shards:  75%|█████████████████████████████████████████████████████████████████▎                     | 3/4 [00:02<00:00,  1.45it/s]Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  2.08it/s]Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.79it/s]
Generating:   0%|                                                                                                             | 0/16 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Generating:   6%|██████▎                                                                                              | 1/16 [00:55<13:50, 55.38s/it]Generating:  12%|████████████▋                                                                                        | 2/16 [01:49<12:45, 54.70s/it]Generating:  19%|██████████████████▉                                                                                  | 3/16 [02:43<11:46, 54.33s/it]Generating:  25%|█████████████████████████▎                                                                           | 4/16 [03:39<10:58, 54.87s/it]Generating:  31%|███████████████████████████████▌                                                                     | 5/16 [04:31<09:54, 54.01s/it]Generating:  38%|█████████████████████████████████████▉                                                               | 6/16 [05:25<08:57, 53.79s/it]Generating:  44%|████████████████████████████████████████████▏                                                        | 7/16 [06:17<08:01, 53.50s/it]Generating:  50%|██████████████████████████████████████████████████▌                                                  | 8/16 [07:10<07:05, 53.20s/it]Generating:  56%|████████████████████████████████████████████████████████▊                                            | 9/16 [08:04<06:14, 53.48s/it]Generating:  62%|██████████████████████████████████████████████████████████████▌                                     | 10/16 [08:56<05:17, 52.96s/it]Generating:  69%|████████████████████████████████████████████████████████████████████▊                               | 11/16 [09:49<04:24, 52.89s/it]Generating:  75%|███████████████████████████████████████████████████████████████████████████                         | 12/16 [10:42<03:32, 53.12s/it]Generating:  81%|█████████████████████████████████████████████████████████████████████████████████▎                  | 13/16 [11:35<02:39, 53.01s/it]Generating:  88%|███████████████████████████████████████████████████████████████████████████████████████▌            | 14/16 [12:31<01:47, 53.93s/it]Generating:  94%|█████████████████████████████████████████████████████████████████████████████████████████████▊      | 15/16 [13:27<00:54, 54.38s/it]Generating: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [14:03<00:00, 48.98s/it]Generating: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [14:03<00:00, 52.71s/it]
Fetching 5 files:   0%|                                                                                                        | 0/5 [00:00<?, ?it/s]Fetching 5 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 1328.40it/s]
Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`
Encoder model frozen.
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 8_self_correction_evaluation_2.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 8_self_correction_evaluation_2.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 8_self_correction_evaluation_2.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 8_self_correction_evaluation_2.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
