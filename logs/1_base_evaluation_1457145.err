+ echo 'Job ID: 1457145'
+ echo 'Job Name: 1_base_evaluation'
+ echo 'Node: gx02'
++ date
+ echo 'Start Time: Sat Nov 29 09:32:41 CET 2025'
++ pwd
+ echo 'Working Directory: /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/sh_files'
+ nvidia-smi
+ cd /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/scripts/
+ export TOKENIZERS_PARALLELISM=false
+ TOKENIZERS_PARALLELISM=false
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ echo 1_base_evaluation
+ python3 1_base_evaluation.py
`torch_dtype` is deprecated! Use `dtype` instead!
We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:12<00:12, 12.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  7.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.52s/it]
Generating:   0%|          | 0/79 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Generating:   1%|▏         | 1/79 [01:52<2:26:50, 112.95s/it]Generating:   3%|▎         | 2/79 [03:45<2:24:38, 112.71s/it]Generating:   4%|▍         | 3/79 [05:34<2:20:23, 110.83s/it]Generating:   5%|▌         | 4/79 [07:23<2:17:58, 110.38s/it]Generating:   6%|▋         | 5/79 [09:08<2:13:45, 108.45s/it]Generating:   8%|▊         | 6/79 [10:52<2:10:06, 106.93s/it]Generating:   9%|▉         | 7/79 [12:46<2:11:00, 109.18s/it]Generating:  10%|█         | 8/79 [14:39<2:10:33, 110.33s/it]Generating:  11%|█▏        | 9/79 [16:29<2:08:31, 110.16s/it]Generating:  13%|█▎        | 10/79 [18:18<2:06:18, 109.83s/it]Generating:  14%|█▍        | 11/79 [20:20<2:08:51, 113.70s/it]Generating:  15%|█▌        | 12/79 [22:05<2:04:01, 111.07s/it]Generating:  16%|█▋        | 13/79 [23:49<1:59:49, 108.93s/it]Generating:  18%|█▊        | 14/79 [25:44<1:59:55, 110.69s/it]Generating:  19%|█▉        | 15/79 [27:44<2:01:03, 113.49s/it]Generating:  20%|██        | 16/79 [29:27<1:55:42, 110.20s/it]Generating:  22%|██▏       | 17/79 [31:19<1:54:37, 110.93s/it]Generating:  23%|██▎       | 18/79 [33:09<1:52:18, 110.47s/it]Generating:  24%|██▍       | 19/79 [35:12<1:54:26, 114.44s/it]Generating:  25%|██▌       | 20/79 [37:04<1:51:44, 113.64s/it]Generating:  27%|██▋       | 21/79 [38:48<1:47:03, 110.75s/it]Generating:  28%|██▊       | 22/79 [40:40<1:45:26, 110.99s/it]Generating:  29%|██▉       | 23/79 [42:22<1:41:12, 108.44s/it]Generating:  30%|███       | 24/79 [44:09<1:38:51, 107.84s/it]Generating:  32%|███▏      | 25/79 [45:50<1:35:19, 105.92s/it]Generating:  33%|███▎      | 26/79 [47:35<1:33:19, 105.65s/it]Generating:  34%|███▍      | 27/79 [49:26<1:33:00, 107.31s/it]Generating:  35%|███▌      | 28/79 [51:09<1:30:10, 106.09s/it]Generating:  37%|███▋      | 29/79 [53:00<1:29:24, 107.30s/it]Generating:  38%|███▊      | 30/79 [54:46<1:27:19, 106.93s/it]Generating:  39%|███▉      | 31/79 [56:34<1:25:57, 107.45s/it]Generating:  41%|████      | 32/79 [58:23<1:24:23, 107.72s/it]Generating:  42%|████▏     | 33/79 [1:00:08<1:21:58, 106.92s/it]Generating:  43%|████▎     | 34/79 [1:01:56<1:20:30, 107.34s/it]Generating:  44%|████▍     | 35/79 [1:03:45<1:18:59, 107.72s/it]Generating:  46%|████▌     | 36/79 [1:05:36<1:17:59, 108.83s/it]Generating:  47%|████▋     | 37/79 [1:07:23<1:15:41, 108.12s/it]Generating:  48%|████▊     | 38/79 [1:09:09<1:13:32, 107.63s/it]Generating:  49%|████▉     | 39/79 [1:11:07<1:13:50, 110.76s/it]Generating:  51%|█████     | 40/79 [1:13:12<1:14:40, 114.88s/it]Generating:  52%|█████▏    | 41/79 [1:15:10<1:13:24, 115.90s/it]Generating:  53%|█████▎    | 42/79 [1:17:02<1:10:45, 114.73s/it]Generating:  54%|█████▍    | 43/79 [1:18:48<1:07:21, 112.26s/it]Generating:  56%|█████▌    | 44/79 [1:20:35<1:04:25, 110.43s/it]Generating:  57%|█████▋    | 45/79 [1:22:29<1:03:11, 111.52s/it]Generating:  58%|█████▊    | 46/79 [1:24:17<1:00:44, 110.44s/it]Generating:  59%|█████▉    | 47/79 [1:26:02<58:05, 108.93s/it]  Generating:  61%|██████    | 48/79 [1:27:55<56:57, 110.25s/it]Generating:  62%|██████▏   | 49/79 [1:29:47<55:18, 110.63s/it]Generating:  63%|██████▎   | 50/79 [1:31:46<54:41, 113.16s/it]Generating:  65%|██████▍   | 51/79 [1:33:36<52:22, 112.23s/it]Generating:  66%|██████▌   | 52/79 [1:35:32<50:59, 113.32s/it]Generating:  67%|██████▋   | 53/79 [1:37:23<48:49, 112.66s/it]Generating:  68%|██████▊   | 54/79 [1:39:12<46:31, 111.66s/it]Generating:  70%|██████▉   | 55/79 [1:40:58<43:54, 109.76s/it]Generating:  71%|███████   | 56/79 [1:42:51<42:31, 110.95s/it]Generating:  72%|███████▏  | 57/79 [1:44:34<39:44, 108.38s/it]Generating:  73%|███████▎  | 58/79 [1:46:25<38:16, 109.38s/it]Generating:  75%|███████▍  | 59/79 [1:48:13<36:18, 108.95s/it]Generating:  76%|███████▌  | 60/79 [1:49:58<34:06, 107.71s/it]Generating:  77%|███████▋  | 61/79 [1:51:49<32:36, 108.68s/it]Generating:  78%|███████▊  | 62/79 [1:53:37<30:43, 108.45s/it]Generating:  80%|███████▉  | 63/79 [1:55:25<28:55, 108.47s/it]Generating:  81%|████████  | 64/79 [1:57:20<27:33, 110.27s/it]Generating:  82%|████████▏ | 65/79 [1:59:11<25:46, 110.46s/it]Generating:  84%|████████▎ | 66/79 [2:01:03<24:00, 110.83s/it]Generating:  85%|████████▍ | 67/79 [2:02:51<22:00, 110.06s/it]Generating:  86%|████████▌ | 68/79 [2:04:37<19:59, 109.05s/it]Generating:  87%|████████▋ | 69/79 [2:06:25<18:07, 108.72s/it]Generating:  89%|████████▊ | 70/79 [2:08:14<16:19, 108.80s/it]Generating:  90%|████████▉ | 71/79 [2:10:05<14:34, 109.36s/it]Generating:  91%|█████████ | 72/79 [2:11:56<12:48, 109.80s/it]Generating:  92%|█████████▏| 73/79 [2:13:42<10:52, 108.82s/it]Generating:  94%|█████████▎| 74/79 [2:15:31<09:03, 108.69s/it]Generating:  95%|█████████▍| 75/79 [2:17:21<07:16, 109.02s/it]Generating:  96%|█████████▌| 76/79 [2:19:09<05:26, 108.72s/it]Generating:  97%|█████████▋| 77/79 [2:20:54<03:35, 107.77s/it]Generating:  99%|█████████▊| 78/79 [2:22:50<01:50, 110.29s/it]Generating: 100%|██████████| 79/79 [2:23:07<00:00, 82.32s/it] Generating: 100%|██████████| 79/79 [2:23:07<00:00, 108.71s/it]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 7653.84it/s]
Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`
Encoder model frozen.
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 1_base_evaluation.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
++ date
+ echo 'Done at: Sat Nov 29 11:58:16 CET 2025'
