+ echo 'Job ID: 1458140'
+ echo 'Job Name: 4_wmt_evaluation_bleu_comet'
+ echo 'Node: gx02'
++ date
+ echo 'Start Time: Sun Nov 30 15:26:56 CET 2025'
++ pwd
+ echo 'Working Directory: /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/sh_files'
+ nvidia-smi
+ cd /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/scripts/
+ export TOKENIZERS_PARALLELISM=false
+ TOKENIZERS_PARALLELISM=false
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ echo 4_wmt_evaluation_bleu_comet
+ python3 4_wmt_evaluation_bleu_comet.py
`torch_dtype` is deprecated! Use `dtype` instead!
We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.17s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.10s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.06it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.01it/s]
Generating:   0%|          | 0/105 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Generating:   1%|          | 1/105 [01:26<2:30:34, 86.87s/it]Generating:   2%|▏         | 2/105 [02:49<2:25:20, 84.66s/it]Generating:   3%|▎         | 3/105 [04:16<2:25:18, 85.47s/it]Generating:   4%|▍         | 4/105 [05:39<2:22:05, 84.42s/it]Generating:   5%|▍         | 5/105 [07:03<2:20:26, 84.26s/it]Generating:   6%|▌         | 6/105 [08:23<2:16:52, 82.96s/it]Generating:   7%|▋         | 7/105 [09:43<2:13:45, 81.89s/it]Generating:   8%|▊         | 8/105 [10:59<2:09:41, 80.22s/it]Generating:   9%|▊         | 9/105 [12:26<2:11:43, 82.32s/it]Generating:  10%|▉         | 10/105 [13:53<2:12:14, 83.52s/it]Generating:  10%|█         | 11/105 [15:17<2:11:02, 83.64s/it]Generating:  11%|█▏        | 12/105 [16:39<2:09:15, 83.39s/it]Generating:  12%|█▏        | 13/105 [18:03<2:07:50, 83.37s/it]Generating:  13%|█▎        | 14/105 [19:32<2:09:03, 85.10s/it]Generating:  14%|█▍        | 15/105 [21:05<2:11:11, 87.46s/it]Generating:  15%|█▌        | 16/105 [22:25<2:06:37, 85.36s/it]Generating:  16%|█▌        | 17/105 [23:45<2:02:41, 83.65s/it]Generating:  17%|█▋        | 18/105 [25:13<2:03:05, 84.89s/it]Generating:  18%|█▊        | 19/105 [26:44<2:04:26, 86.81s/it]Generating:  19%|█▉        | 20/105 [28:05<2:00:39, 85.17s/it]Generating:  20%|██        | 21/105 [29:24<1:56:29, 83.21s/it]Generating:  21%|██        | 22/105 [30:45<1:54:24, 82.71s/it]Generating:  22%|██▏       | 23/105 [32:12<1:54:25, 83.73s/it]Generating:  23%|██▎       | 24/105 [33:35<1:53:03, 83.75s/it]Generating:  24%|██▍       | 25/105 [35:09<1:55:26, 86.58s/it]Generating:  25%|██▍       | 26/105 [36:34<1:53:31, 86.22s/it]Generating:  26%|██▌       | 27/105 [37:57<1:50:42, 85.16s/it]Generating:  27%|██▋       | 28/105 [39:16<1:47:04, 83.43s/it]Generating:  28%|██▊       | 29/105 [40:41<1:46:23, 84.00s/it]Generating:  29%|██▊       | 30/105 [42:00<1:42:57, 82.37s/it]Generating:  30%|██▉       | 31/105 [43:17<1:39:49, 80.94s/it]Generating:  30%|███       | 32/105 [44:39<1:38:44, 81.15s/it]Generating:  31%|███▏      | 33/105 [45:57<1:36:08, 80.11s/it]Generating:  32%|███▏      | 34/105 [47:17<1:34:55, 80.21s/it]Generating:  33%|███▎      | 35/105 [48:38<1:33:41, 80.30s/it]Generating:  34%|███▍      | 36/105 [50:03<1:34:05, 81.81s/it]Generating:  35%|███▌      | 37/105 [51:23<1:31:53, 81.09s/it]Generating:  36%|███▌      | 38/105 [52:40<1:29:23, 80.05s/it]Generating:  37%|███▋      | 39/105 [54:04<1:29:26, 81.31s/it]Generating:  38%|███▊      | 40/105 [55:26<1:28:06, 81.34s/it]Generating:  39%|███▉      | 41/105 [56:45<1:26:03, 80.67s/it]Generating:  40%|████      | 42/105 [58:08<1:25:32, 81.47s/it]Generating:  41%|████      | 43/105 [59:31<1:24:38, 81.92s/it]Generating:  42%|████▏     | 44/105 [1:00:52<1:22:50, 81.48s/it]Generating:  43%|████▎     | 45/105 [1:02:15<1:21:53, 81.90s/it]Generating:  44%|████▍     | 46/105 [1:03:36<1:20:27, 81.83s/it]Generating:  45%|████▍     | 47/105 [1:05:00<1:19:31, 82.28s/it]Generating:  46%|████▌     | 48/105 [1:06:25<1:18:57, 83.12s/it]Generating:  47%|████▋     | 49/105 [1:07:42<1:16:00, 81.45s/it]Generating:  48%|████▊     | 50/105 [1:09:04<1:14:41, 81.48s/it]Generating:  49%|████▊     | 51/105 [1:10:23<1:12:50, 80.93s/it]Generating:  50%|████▉     | 52/105 [1:11:53<1:13:50, 83.59s/it]Generating:  50%|█████     | 53/105 [1:13:19<1:13:06, 84.36s/it]Generating:  51%|█████▏    | 54/105 [1:14:53<1:14:12, 87.30s/it]Generating:  52%|█████▏    | 55/105 [1:16:19<1:12:19, 86.80s/it]Generating:  53%|█████▎    | 56/105 [1:17:42<1:09:55, 85.63s/it]Generating:  54%|█████▍    | 57/105 [1:19:04<1:07:33, 84.44s/it]Generating:  55%|█████▌    | 58/105 [1:20:25<1:05:25, 83.52s/it]Generating:  56%|█████▌    | 59/105 [1:21:49<1:04:04, 83.58s/it]Generating:  57%|█████▋    | 60/105 [1:23:16<1:03:30, 84.69s/it]Generating:  58%|█████▊    | 61/105 [1:24:39<1:01:40, 84.10s/it]Generating:  59%|█████▉    | 62/105 [1:26:00<59:34, 83.12s/it]  Generating:  60%|██████    | 63/105 [1:27:26<58:56, 84.21s/it]Generating:  61%|██████    | 64/105 [1:28:47<56:45, 83.06s/it]Generating:  62%|██████▏   | 65/105 [1:30:11<55:41, 83.54s/it]Generating:  63%|██████▎   | 66/105 [1:31:42<55:37, 85.57s/it]Generating:  64%|██████▍   | 67/105 [1:33:01<53:01, 83.73s/it]Generating:  65%|██████▍   | 68/105 [1:34:25<51:44, 83.90s/it]Generating:  66%|██████▌   | 69/105 [1:35:44<49:22, 82.30s/it]Generating:  67%|██████▋   | 70/105 [1:37:13<49:09, 84.27s/it]Generating:  68%|██████▊   | 71/105 [1:38:38<47:51, 84.44s/it]Generating:  69%|██████▊   | 72/105 [1:40:02<46:20, 84.25s/it]Generating:  70%|██████▉   | 73/105 [1:41:22<44:22, 83.19s/it]Generating:  70%|███████   | 74/105 [1:42:49<43:34, 84.34s/it]Generating:  71%|███████▏  | 75/105 [1:44:10<41:42, 83.41s/it]Generating:  72%|███████▏  | 76/105 [1:45:29<39:34, 81.88s/it]Generating:  73%|███████▎  | 77/105 [1:46:54<38:42, 82.94s/it]Generating:  74%|███████▍  | 78/105 [1:48:17<37:17, 82.86s/it]Generating:  75%|███████▌  | 79/105 [1:49:39<35:51, 82.74s/it]Generating:  76%|███████▌  | 80/105 [1:51:00<34:09, 81.98s/it]Generating:  77%|███████▋  | 81/105 [1:52:24<33:08, 82.85s/it]Generating:  78%|███████▊  | 82/105 [1:53:47<31:44, 82.79s/it]Generating:  79%|███████▉  | 83/105 [1:55:09<30:13, 82.42s/it]Generating:  80%|████████  | 84/105 [1:56:32<28:53, 82.55s/it]Generating:  81%|████████  | 85/105 [1:57:59<28:00, 84.03s/it]Generating:  82%|████████▏ | 86/105 [1:59:24<26:41, 84.32s/it]Generating:  83%|████████▎ | 87/105 [2:00:48<25:14, 84.13s/it]Generating:  84%|████████▍ | 88/105 [2:02:13<23:56, 84.52s/it]Generating:  85%|████████▍ | 89/105 [2:03:36<22:24, 84.03s/it]Generating:  86%|████████▌ | 90/105 [2:04:55<20:37, 82.50s/it]Generating:  87%|████████▋ | 91/105 [2:06:17<19:14, 82.49s/it]Generating:  88%|████████▊ | 92/105 [2:07:40<17:53, 82.54s/it]Generating:  89%|████████▊ | 93/105 [2:09:03<16:32, 82.75s/it]Generating:  90%|████████▉ | 94/105 [2:10:22<14:56, 81.46s/it]Generating:  90%|█████████ | 95/105 [2:11:46<13:44, 82.44s/it]Generating:  91%|█████████▏| 96/105 [2:13:11<12:28, 83.18s/it]Generating:  92%|█████████▏| 97/105 [2:14:33<11:01, 82.71s/it]Generating:  93%|█████████▎| 98/105 [2:15:55<09:38, 82.64s/it]Generating:  94%|█████████▍| 99/105 [2:17:18<08:16, 82.71s/it]Generating:  95%|█████████▌| 100/105 [2:18:42<06:55, 83.12s/it]Generating:  96%|█████████▌| 101/105 [2:20:02<05:28, 82.00s/it]Generating:  97%|█████████▋| 102/105 [2:21:25<04:06, 82.23s/it]Generating:  98%|█████████▊| 103/105 [2:22:54<02:48, 84.26s/it]Generating:  99%|█████████▉| 104/105 [2:24:16<01:23, 83.62s/it]Generating: 100%|██████████| 105/105 [2:24:33<00:00, 63.64s/it]Generating: 100%|██████████| 105/105 [2:24:33<00:00, 82.60s/it]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 5297.18it/s]
Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`
Encoder model frozen.
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 4_wmt_evaluation_bleu_comet.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 4_wmt_evaluation_bleu_comet.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
++ date
+ echo 'Done at: Sun Nov 30 17:53:45 CET 2025'
