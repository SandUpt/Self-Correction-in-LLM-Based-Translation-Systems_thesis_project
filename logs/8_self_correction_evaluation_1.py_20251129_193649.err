`torch_dtype` is deprecated! Use `dtype` instead!
We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|                                                                                               | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|█████████████████████████████                                                          | 1/3 [00:00<00:01,  1.33it/s]Loading checkpoint shards:  67%|██████████████████████████████████████████████████████████                             | 2/3 [00:01<00:00,  1.35it/s]Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.53it/s]Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.47it/s]
Generating:   0%|                                                                                                             | 0/32 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Generating:   3%|███▏                                                                                                 | 1/32 [00:59<30:55, 59.85s/it]Generating:   6%|██████▎                                                                                              | 2/32 [01:57<29:20, 58.70s/it]Generating:   9%|█████████▍                                                                                           | 3/32 [02:53<27:42, 57.34s/it]Generating:  12%|████████████▋                                                                                        | 4/32 [03:50<26:46, 57.39s/it]Generating:  16%|███████████████▊                                                                                     | 5/32 [04:48<25:48, 57.34s/it]Generating:  19%|██████████████████▉                                                                                  | 6/32 [05:43<24:35, 56.75s/it]Generating:  22%|██████████████████████                                                                               | 7/32 [06:43<24:03, 57.72s/it]Generating:  25%|█████████████████████████▎                                                                           | 8/32 [07:39<22:50, 57.09s/it]Generating:  28%|████████████████████████████▍                                                                        | 9/32 [08:33<21:29, 56.08s/it]Generating:  31%|███████████████████████████████▎                                                                    | 10/32 [09:26<20:18, 55.40s/it]Generating:  34%|██████████████████████████████████▍                                                                 | 11/32 [10:22<19:22, 55.38s/it]Generating:  38%|█████████████████████████████████████▌                                                              | 12/32 [11:17<18:28, 55.44s/it]Generating:  41%|████████████████████████████████████████▋                                                           | 13/32 [12:15<17:43, 55.98s/it]Generating:  44%|███████████████████████████████████████████▊                                                        | 14/32 [13:09<16:39, 55.53s/it]Generating:  47%|██████████████████████████████████████████████▉                                                     | 15/32 [14:04<15:38, 55.21s/it]Generating:  50%|██████████████████████████████████████████████████                                                  | 16/32 [14:57<14:35, 54.74s/it]Generating:  53%|█████████████████████████████████████████████████████▏                                              | 17/32 [15:51<13:38, 54.59s/it]Generating:  56%|████████████████████████████████████████████████████████▎                                           | 18/32 [16:50<13:00, 55.78s/it]Generating:  59%|███████████████████████████████████████████████████████████▍                                        | 19/32 [17:43<11:53, 54.87s/it]Generating:  62%|██████████████████████████████████████████████████████████████▌                                     | 20/32 [18:37<10:57, 54.75s/it]Generating:  66%|█████████████████████████████████████████████████████████████████▋                                  | 21/32 [19:31<10:00, 54.59s/it]Generating:  69%|████████████████████████████████████████████████████████████████████▊                               | 22/32 [20:26<09:05, 54.57s/it]Generating:  72%|███████████████████████████████████████████████████████████████████████▉                            | 23/32 [21:22<08:16, 55.12s/it]Generating:  75%|███████████████████████████████████████████████████████████████████████████                         | 24/32 [22:19<07:23, 55.49s/it]Generating:  78%|██████████████████████████████████████████████████████████████████████████████▏                     | 25/32 [23:13<06:25, 55.07s/it]Generating:  81%|█████████████████████████████████████████████████████████████████████████████████▎                  | 26/32 [24:08<05:30, 55.12s/it]Generating:  84%|████████████████████████████████████████████████████████████████████████████████████▍               | 27/32 [25:02<04:33, 54.64s/it]Generating:  88%|███████████████████████████████████████████████████████████████████████████████████████▌            | 28/32 [26:02<03:45, 56.29s/it]Generating:  91%|██████████████████████████████████████████████████████████████████████████████████████████▋         | 29/32 [26:58<02:49, 56.41s/it]Generating:  94%|█████████████████████████████████████████████████████████████████████████████████████████████▊      | 30/32 [27:56<01:53, 56.88s/it]Generating:  97%|████████████████████████████████████████████████████████████████████████████████████████████████▉   | 31/32 [28:51<00:56, 56.29s/it]Generating: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [29:09<00:00, 44.79s/it]Generating: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [29:09<00:00, 54.68s/it]
Fetching 5 files:   0%|                                                                                                        | 0/5 [00:00<?, ?it/s]Fetching 5 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 3014.45it/s]
Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`
Encoder model frozen.
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 8_self_correction_evaluation_1.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 8_self_correction_evaluation_1.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 8_self_correction_evaluation_1.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 8_self_correction_evaluation_1.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
