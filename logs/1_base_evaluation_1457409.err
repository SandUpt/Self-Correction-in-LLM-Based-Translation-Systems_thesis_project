+ echo 'Job ID: 1457409'
+ echo 'Job Name: 1_base_evaluation'
+ echo 'Node: gx25'
++ date
+ echo 'Start Time: Sat Nov 29 16:46:05 CET 2025'
++ pwd
+ echo 'Working Directory: /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/sh_files'
+ nvidia-smi
+ cd /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/scripts/
+ export TOKENIZERS_PARALLELISM=false
+ TOKENIZERS_PARALLELISM=false
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ echo 1_base_evaluation
+ python3 1_base_evaluation.py
`torch_dtype` is deprecated! Use `dtype` instead!
We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.00it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]
Generating:   0%|          | 0/157 [00:00<?, ?it/s]Generating:   1%|          | 1/157 [00:07<19:56,  7.67s/it]Generating:   1%|▏         | 2/157 [00:15<20:45,  8.04s/it]Generating:   2%|▏         | 3/157 [00:22<18:27,  7.19s/it]Generating:   3%|▎         | 4/157 [00:31<20:59,  8.23s/it]Generating:   3%|▎         | 5/157 [00:47<27:32, 10.87s/it]Generating:   4%|▍         | 6/157 [00:55<24:51,  9.88s/it]Generating:   4%|▍         | 7/157 [01:00<20:48,  8.32s/it]Generating:   5%|▌         | 8/157 [01:08<20:25,  8.22s/it]Generating:   6%|▌         | 9/157 [01:15<19:09,  7.77s/it]Generating:   6%|▋         | 10/157 [01:21<17:33,  7.17s/it]Generating:   7%|▋         | 11/157 [01:27<16:50,  6.92s/it]Generating:   8%|▊         | 12/157 [01:34<16:22,  6.78s/it]Generating:   8%|▊         | 13/157 [01:41<17:06,  7.13s/it]Generating:   9%|▉         | 14/157 [01:48<16:49,  7.06s/it]Generating:  10%|▉         | 15/157 [01:56<17:18,  7.31s/it]Generating:  10%|█         | 16/157 [02:02<16:13,  6.90s/it]Generating:  11%|█         | 17/157 [02:09<15:51,  6.80s/it]Generating:  11%|█▏        | 18/157 [02:19<18:23,  7.94s/it]Generating:  12%|█▏        | 19/157 [02:28<18:28,  8.03s/it]Generating:  13%|█▎        | 20/157 [02:34<17:10,  7.52s/it]Generating:  13%|█▎        | 21/157 [02:42<17:29,  7.72s/it]Generating:  14%|█▍        | 22/157 [02:51<18:01,  8.01s/it]Generating:  15%|█▍        | 23/157 [02:58<17:34,  7.87s/it]Generating:  15%|█▌        | 24/157 [03:05<16:36,  7.49s/it]Generating:  16%|█▌        | 25/157 [03:14<17:44,  8.06s/it]Generating:  17%|█▋        | 26/157 [03:44<31:31, 14.44s/it]Generating:  17%|█▋        | 27/157 [04:14<41:36, 19.21s/it]Generating:  18%|█▊        | 28/157 [04:23<34:33, 16.07s/it]Generating:  18%|█▊        | 29/157 [04:31<29:03, 13.62s/it]Generating:  19%|█▉        | 30/157 [04:38<24:35, 11.62s/it]Generating:  20%|█▉        | 31/157 [04:47<23:01, 10.96s/it]Generating:  20%|██        | 32/157 [04:54<20:10,  9.69s/it]Generating:  21%|██        | 33/157 [05:24<32:56, 15.94s/it]Generating:  22%|██▏       | 34/157 [05:32<27:55, 13.62s/it]Generating:  22%|██▏       | 35/157 [05:39<23:16, 11.45s/it]Generating:  23%|██▎       | 36/157 [05:45<19:59,  9.92s/it]Generating:  24%|██▎       | 37/157 [05:52<18:05,  9.05s/it]Generating:  24%|██▍       | 38/157 [06:01<17:52,  9.02s/it]Generating:  25%|██▍       | 39/157 [06:31<30:16, 15.40s/it]Generating:  25%|██▌       | 40/157 [06:40<25:51, 13.26s/it]Generating:  26%|██▌       | 41/157 [06:45<21:15, 10.99s/it]Generating:  27%|██▋       | 42/157 [06:53<18:53,  9.85s/it]Generating:  27%|██▋       | 43/157 [07:02<18:10,  9.56s/it]Generating:  28%|██▊       | 44/157 [07:08<16:28,  8.75s/it]Generating:  29%|██▊       | 45/157 [07:14<14:49,  7.94s/it]Generating:  29%|██▉       | 46/157 [07:21<13:40,  7.39s/it]Generating:  30%|██▉       | 47/157 [07:27<13:10,  7.19s/it]Generating:  31%|███       | 48/157 [07:34<12:50,  7.07s/it]Generating:  31%|███       | 49/157 [08:02<23:58, 13.32s/it]Generating:  32%|███▏      | 50/157 [08:08<19:37, 11.00s/it]Generating:  32%|███▏      | 51/157 [08:15<17:30,  9.91s/it]Generating:  33%|███▎      | 52/157 [08:22<15:52,  9.07s/it]Generating:  34%|███▍      | 53/157 [08:31<15:26,  8.91s/it]Generating:  34%|███▍      | 54/157 [08:37<14:01,  8.17s/it]Generating:  35%|███▌      | 55/157 [08:43<12:42,  7.47s/it]Generating:  36%|███▌      | 56/157 [08:49<12:00,  7.13s/it]Generating:  36%|███▋      | 57/157 [08:55<11:21,  6.82s/it]Generating:  37%|███▋      | 58/157 [09:04<12:09,  7.37s/it]Generating:  38%|███▊      | 59/157 [09:11<11:51,  7.26s/it]Generating:  38%|███▊      | 60/157 [09:17<11:14,  6.95s/it]Generating:  39%|███▉      | 61/157 [09:24<10:57,  6.85s/it]Generating:  39%|███▉      | 62/157 [09:31<11:00,  6.95s/it]Generating:  40%|████      | 63/157 [09:38<10:45,  6.87s/it]Generating:  41%|████      | 64/157 [09:45<11:04,  7.15s/it]Generating:  41%|████▏     | 65/157 [10:14<20:43, 13.51s/it]Generating:  42%|████▏     | 66/157 [10:21<17:26, 11.50s/it]Generating:  43%|████▎     | 67/157 [10:28<15:37, 10.41s/it]Generating:  43%|████▎     | 68/157 [10:35<13:42,  9.24s/it]Generating:  44%|████▍     | 69/157 [10:42<12:46,  8.71s/it]Generating:  45%|████▍     | 70/157 [10:50<12:17,  8.48s/it]Generating:  45%|████▌     | 71/157 [10:57<11:12,  7.82s/it]Generating:  46%|████▌     | 72/157 [11:04<10:42,  7.56s/it]Generating:  46%|████▋     | 73/157 [11:10<09:54,  7.08s/it]Generating:  47%|████▋     | 74/157 [11:17<09:50,  7.11s/it]Generating:  48%|████▊     | 75/157 [11:23<09:22,  6.86s/it]Generating:  48%|████▊     | 76/157 [11:29<08:50,  6.55s/it]Generating:  49%|████▉     | 77/157 [11:50<14:33, 10.92s/it]Generating:  50%|████▉     | 78/157 [12:21<22:11, 16.86s/it]Generating:  50%|█████     | 79/157 [12:27<17:56, 13.81s/it]Generating:  51%|█████     | 80/157 [13:01<25:14, 19.67s/it]Generating:  52%|█████▏    | 81/157 [13:32<29:25, 23.24s/it]Generating:  52%|█████▏    | 82/157 [13:40<23:09, 18.53s/it]Generating:  53%|█████▎    | 83/157 [13:49<19:16, 15.63s/it]Generating:  54%|█████▎    | 84/157 [13:55<15:39, 12.87s/it]Generating:  54%|█████▍    | 85/157 [14:01<13:01, 10.85s/it]Generating:  55%|█████▍    | 86/157 [14:08<11:18,  9.55s/it]Generating:  55%|█████▌    | 87/157 [14:15<10:19,  8.86s/it]Generating:  56%|█████▌    | 88/157 [14:21<09:09,  7.97s/it]Generating:  57%|█████▋    | 89/157 [14:30<09:31,  8.40s/it]Generating:  57%|█████▋    | 90/157 [14:36<08:22,  7.51s/it]Generating:  58%|█████▊    | 91/157 [14:42<07:52,  7.16s/it]Generating:  59%|█████▊    | 92/157 [14:48<07:28,  6.89s/it]Generating:  59%|█████▉    | 93/157 [14:56<07:33,  7.08s/it]Generating:  60%|█████▉    | 94/157 [15:03<07:18,  6.96s/it]Generating:  61%|██████    | 95/157 [15:16<09:03,  8.77s/it]Generating:  61%|██████    | 96/157 [15:22<08:11,  8.05s/it]Generating:  62%|██████▏   | 97/157 [15:28<07:35,  7.59s/it]Generating:  62%|██████▏   | 98/157 [15:37<07:46,  7.91s/it]Generating:  63%|██████▎   | 99/157 [15:46<07:59,  8.27s/it]Generating:  64%|██████▎   | 100/157 [15:53<07:17,  7.67s/it]Generating:  64%|██████▍   | 101/157 [16:02<07:32,  8.08s/it]Generating:  65%|██████▍   | 102/157 [16:08<07:02,  7.67s/it]Generating:  66%|██████▌   | 103/157 [16:37<12:32, 13.94s/it]Generating:  66%|██████▌   | 104/157 [16:44<10:33, 11.96s/it]Generating:  67%|██████▋   | 105/157 [17:14<14:57, 17.27s/it]Generating:  68%|██████▊   | 106/157 [17:21<12:08, 14.28s/it]Generating:  68%|██████▊   | 107/157 [17:30<10:36, 12.73s/it]Generating:  69%|██████▉   | 108/157 [17:38<09:06, 11.16s/it]Generating:  69%|██████▉   | 109/157 [17:44<07:40,  9.59s/it]Generating:  70%|███████   | 110/157 [17:50<06:50,  8.73s/it]Generating:  71%|███████   | 111/157 [17:58<06:22,  8.33s/it]Generating:  71%|███████▏  | 112/157 [18:04<05:48,  7.75s/it]Generating:  72%|███████▏  | 113/157 [18:10<05:13,  7.13s/it]Generating:  73%|███████▎  | 114/157 [18:16<04:51,  6.78s/it]Generating:  73%|███████▎  | 115/157 [18:24<05:03,  7.24s/it]Generating:  74%|███████▍  | 116/157 [18:31<04:54,  7.20s/it]Generating:  75%|███████▍  | 117/157 [18:38<04:38,  6.96s/it]Generating:  75%|███████▌  | 118/157 [18:44<04:30,  6.93s/it]Generating:  76%|███████▌  | 119/157 [18:52<04:31,  7.14s/it]Generating:  76%|███████▋  | 120/157 [18:58<04:11,  6.80s/it]Generating:  77%|███████▋  | 121/157 [19:06<04:21,  7.26s/it]Generating:  78%|███████▊  | 122/157 [19:13<04:05,  7.02s/it]Generating:  78%|███████▊  | 123/157 [19:20<03:58,  7.01s/it]Generating:  79%|███████▉  | 124/157 [19:28<03:59,  7.27s/it]Generating:  80%|███████▉  | 125/157 [19:36<04:02,  7.59s/it]Generating:  80%|████████  | 126/157 [19:43<03:46,  7.31s/it]Generating:  81%|████████  | 127/157 [19:51<03:48,  7.60s/it]Generating:  82%|████████▏ | 128/157 [20:02<04:07,  8.54s/it]Generating:  82%|████████▏ | 129/157 [20:10<03:56,  8.46s/it]Generating:  83%|████████▎ | 130/157 [20:18<03:44,  8.31s/it]Generating:  83%|████████▎ | 131/157 [20:25<03:26,  7.92s/it]Generating:  84%|████████▍ | 132/157 [20:33<03:21,  8.04s/it]Generating:  85%|████████▍ | 133/157 [20:40<03:04,  7.67s/it]Generating:  85%|████████▌ | 134/157 [20:46<02:42,  7.05s/it]Generating:  86%|████████▌ | 135/157 [20:52<02:27,  6.69s/it]Generating:  87%|████████▋ | 136/157 [20:59<02:22,  6.78s/it]Generating:  87%|████████▋ | 137/157 [21:08<02:28,  7.44s/it]Generating:  88%|████████▊ | 138/157 [21:15<02:23,  7.58s/it]Generating:  89%|████████▊ | 139/157 [21:23<02:16,  7.58s/it]Generating:  89%|████████▉ | 140/157 [21:28<01:57,  6.93s/it]Generating:  90%|████████▉ | 141/157 [21:34<01:46,  6.63s/it]Generating:  90%|█████████ | 142/157 [21:42<01:44,  6.97s/it]Generating:  91%|█████████ | 143/157 [21:55<02:03,  8.81s/it]Generating:  92%|█████████▏| 144/157 [22:03<01:50,  8.47s/it]Generating:  92%|█████████▏| 145/157 [22:09<01:32,  7.70s/it]Generating:  93%|█████████▎| 146/157 [22:16<01:23,  7.60s/it]Generating:  94%|█████████▎| 147/157 [22:23<01:13,  7.37s/it]Generating:  94%|█████████▍| 148/157 [22:31<01:06,  7.42s/it]Generating:  95%|█████████▍| 149/157 [22:44<01:14,  9.28s/it]Generating:  96%|█████████▌| 150/157 [22:51<01:00,  8.62s/it]Generating:  96%|█████████▌| 151/157 [22:59<00:49,  8.29s/it]Generating:  97%|█████████▋| 152/157 [23:05<00:37,  7.58s/it]Generating:  97%|█████████▋| 153/157 [23:12<00:29,  7.38s/it]Generating:  98%|█████████▊| 154/157 [23:18<00:20,  6.94s/it]Generating:  99%|█████████▊| 155/157 [23:25<00:14,  7.16s/it]Generating:  99%|█████████▉| 156/157 [23:32<00:07,  7.09s/it]Generating: 100%|██████████| 157/157 [23:35<00:00,  5.71s/it]Generating: 100%|██████████| 157/157 [23:35<00:00,  9.01s/it]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 3362.98it/s]
Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`
Encoder model frozen.
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 1_base_evaluation.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
++ date
+ echo 'Done at: Sat Nov 29 17:11:44 CET 2025'
