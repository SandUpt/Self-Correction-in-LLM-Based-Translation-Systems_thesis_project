+ echo 'Job ID: 1457271'
+ echo 'Job Name: 1_base_evaluation'
+ echo 'Node: gx25'
++ date
+ echo 'Start Time: Sat Nov 29 12:52:59 CET 2025'
++ pwd
+ echo 'Working Directory: /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/sh_files'
+ nvidia-smi
+ cd /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/scripts/
+ export TOKENIZERS_PARALLELISM=false
+ TOKENIZERS_PARALLELISM=false
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ echo 1_base_evaluation
+ python3 1_base_evaluation.py
`torch_dtype` is deprecated! Use `dtype` instead!
We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:16<00:16, 16.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 11.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 12.39s/it]
Generating:   0%|          | 0/157 [00:00<?, ?it/s]Generating:   1%|          | 1/157 [00:09<23:41,  9.11s/it]Generating:   1%|▏         | 2/157 [00:14<17:16,  6.69s/it]Generating:   2%|▏         | 3/157 [00:20<17:08,  6.68s/it]Generating:   3%|▎         | 4/157 [00:27<16:48,  6.59s/it]Generating:   3%|▎         | 5/157 [00:34<17:32,  6.93s/it]Generating:   4%|▍         | 6/157 [00:46<21:27,  8.53s/it]Generating:   4%|▍         | 7/157 [00:52<19:36,  7.84s/it]Generating:   5%|▌         | 8/157 [01:00<19:29,  7.85s/it]Generating:   6%|▌         | 9/157 [01:08<19:24,  7.87s/it]Generating:   6%|▋         | 10/157 [01:44<40:24, 16.49s/it]Generating:   7%|▋         | 11/157 [01:52<34:13, 14.07s/it]Generating:   8%|▊         | 12/157 [01:58<28:04, 11.62s/it]Generating:   8%|▊         | 13/157 [02:20<34:53, 14.54s/it]Generating:   9%|▉         | 14/157 [02:27<29:07, 12.22s/it]Generating:  10%|▉         | 15/157 [02:35<25:52, 10.93s/it]Generating:  10%|█         | 16/157 [02:41<22:48,  9.71s/it]Generating:  11%|█         | 17/157 [02:49<20:52,  8.94s/it]Generating:  11%|█▏        | 18/157 [02:57<20:12,  8.72s/it]Generating:  12%|█▏        | 19/157 [03:03<18:37,  8.10s/it]Generating:  13%|█▎        | 20/157 [03:12<18:52,  8.26s/it]Generating:  13%|█▎        | 21/157 [03:18<17:26,  7.69s/it]Generating:  14%|█▍        | 22/157 [03:25<16:21,  7.27s/it]Generating:  15%|█▍        | 23/157 [03:31<15:46,  7.06s/it]Generating:  15%|█▌        | 24/157 [03:43<18:30,  8.35s/it]Generating:  16%|█▌        | 25/157 [03:51<18:18,  8.32s/it]Generating:  17%|█▋        | 26/157 [03:58<17:05,  7.83s/it]Generating:  17%|█▋        | 27/157 [04:06<17:02,  7.87s/it]Generating:  18%|█▊        | 28/157 [04:12<15:58,  7.43s/it]Generating:  18%|█▊        | 29/157 [04:17<14:07,  6.62s/it]Generating:  19%|█▉        | 30/157 [04:23<13:54,  6.57s/it]Generating:  20%|█▉        | 31/157 [04:28<13:00,  6.19s/it]Generating:  20%|██        | 32/157 [04:35<13:08,  6.31s/it]Generating:  21%|██        | 33/157 [04:41<12:45,  6.17s/it]Generating:  22%|██▏       | 34/157 [04:57<18:50,  9.19s/it]Generating:  22%|██▏       | 35/157 [05:05<18:03,  8.88s/it]Generating:  23%|██▎       | 36/157 [05:13<17:17,  8.57s/it]Generating:  24%|██▎       | 37/157 [05:28<20:55, 10.47s/it]Generating:  24%|██▍       | 38/157 [05:33<17:14,  8.69s/it]Generating:  25%|██▍       | 39/157 [05:37<14:48,  7.53s/it]Generating:  25%|██▌       | 40/157 [05:44<14:07,  7.24s/it]Generating:  26%|██▌       | 41/157 [05:51<13:43,  7.10s/it]Generating:  27%|██▋       | 42/157 [05:56<12:24,  6.48s/it]Generating:  27%|██▋       | 43/157 [06:04<13:09,  6.92s/it]Generating:  28%|██▊       | 44/157 [06:12<13:34,  7.21s/it]Generating:  29%|██▊       | 45/157 [06:17<12:20,  6.62s/it]Generating:  29%|██▉       | 46/157 [06:25<12:57,  7.00s/it]Generating:  30%|██▉       | 47/157 [06:31<12:20,  6.73s/it]Generating:  31%|███       | 48/157 [06:39<12:50,  7.07s/it]Generating:  31%|███       | 49/157 [06:48<14:10,  7.87s/it]Generating:  32%|███▏      | 50/157 [06:57<14:14,  7.99s/it]Generating:  32%|███▏      | 51/157 [07:05<14:05,  7.98s/it]Generating:  33%|███▎      | 52/157 [07:10<12:32,  7.17s/it]Generating:  34%|███▍      | 53/157 [07:18<12:41,  7.32s/it]Generating:  34%|███▍      | 54/157 [07:26<13:00,  7.58s/it]Generating:  35%|███▌      | 55/157 [07:34<13:15,  7.80s/it]Generating:  36%|███▌      | 56/157 [07:49<16:38,  9.88s/it]Generating:  36%|███▋      | 57/157 [07:56<15:20,  9.21s/it]Generating:  37%|███▋      | 58/157 [08:01<13:07,  7.95s/it]Generating:  38%|███▊      | 59/157 [08:08<12:13,  7.48s/it]Generating:  38%|███▊      | 60/157 [08:15<11:48,  7.30s/it]Generating:  39%|███▉      | 61/157 [08:25<13:17,  8.31s/it]Generating:  39%|███▉      | 62/157 [08:32<12:19,  7.79s/it]Generating:  40%|████      | 63/157 [08:37<10:54,  6.96s/it]Generating:  41%|████      | 64/157 [08:45<11:03,  7.14s/it]Generating:  41%|████▏     | 65/157 [08:53<11:20,  7.40s/it]Generating:  42%|████▏     | 66/157 [08:59<10:49,  7.14s/it]Generating:  43%|████▎     | 67/157 [09:07<11:05,  7.40s/it]Generating:  43%|████▎     | 68/157 [09:14<10:32,  7.10s/it]Generating:  44%|████▍     | 69/157 [09:19<09:34,  6.53s/it]Generating:  45%|████▍     | 70/157 [09:25<09:19,  6.43s/it]Generating:  45%|████▌     | 71/157 [09:32<09:28,  6.61s/it]Generating:  46%|████▌     | 72/157 [09:49<13:53,  9.80s/it]Generating:  46%|████▋     | 73/157 [09:58<13:07,  9.38s/it]Generating:  47%|████▋     | 74/157 [10:04<11:50,  8.56s/it]Generating:  48%|████▊     | 75/157 [10:12<11:17,  8.26s/it]Generating:  48%|████▊     | 76/157 [10:18<10:25,  7.72s/it]Generating:  49%|████▉     | 77/157 [10:25<09:43,  7.29s/it]Generating:  50%|████▉     | 78/157 [10:31<09:19,  7.08s/it]Generating:  50%|█████     | 79/157 [10:38<09:04,  6.98s/it]Generating:  51%|█████     | 80/157 [10:43<08:14,  6.42s/it]Generating:  52%|█████▏    | 81/157 [10:49<08:05,  6.39s/it]Generating:  52%|█████▏    | 82/157 [10:56<08:01,  6.41s/it]Generating:  53%|█████▎    | 83/157 [11:01<07:30,  6.09s/it]Generating:  54%|█████▎    | 84/157 [11:09<07:58,  6.55s/it]Generating:  54%|█████▍    | 85/157 [11:16<07:56,  6.62s/it]Generating:  55%|█████▍    | 86/157 [11:21<07:17,  6.16s/it]Generating:  55%|█████▌    | 87/157 [11:30<08:17,  7.11s/it]Generating:  56%|█████▌    | 88/157 [11:38<08:28,  7.37s/it]Generating:  57%|█████▋    | 89/157 [11:43<07:29,  6.62s/it]Generating:  57%|█████▋    | 90/157 [11:48<06:52,  6.15s/it]Generating:  58%|█████▊    | 91/157 [11:59<08:27,  7.69s/it]Generating:  59%|█████▊    | 92/157 [12:08<08:42,  8.04s/it]Generating:  59%|█████▉    | 93/157 [12:21<10:11,  9.55s/it]Generating:  60%|█████▉    | 94/157 [12:31<10:11,  9.70s/it]Generating:  61%|██████    | 95/157 [12:38<09:03,  8.76s/it]Generating:  61%|██████    | 96/157 [12:44<08:10,  8.04s/it]Generating:  62%|██████▏   | 97/157 [12:57<09:28,  9.48s/it]Generating:  62%|██████▏   | 98/157 [13:05<08:59,  9.15s/it]Generating:  63%|██████▎   | 99/157 [13:11<07:59,  8.26s/it]Generating:  64%|██████▎   | 100/157 [13:55<17:49, 18.77s/it]Generating:  64%|██████▍   | 101/157 [14:01<14:04, 15.08s/it]Generating:  65%|██████▍   | 102/157 [14:11<12:26, 13.58s/it]Generating:  66%|██████▌   | 103/157 [14:18<10:19, 11.47s/it]Generating:  66%|██████▌   | 104/157 [14:26<09:14, 10.45s/it]Generating:  67%|██████▋   | 105/157 [14:32<08:02,  9.28s/it]Generating:  68%|██████▊   | 106/157 [14:39<07:08,  8.39s/it]Generating:  68%|██████▊   | 107/157 [14:45<06:34,  7.90s/it]Generating:  69%|██████▉   | 108/157 [14:52<06:02,  7.41s/it]Generating:  69%|██████▉   | 109/157 [14:58<05:42,  7.14s/it]Generating:  70%|███████   | 110/157 [15:06<05:50,  7.45s/it]Generating:  71%|███████   | 111/157 [15:13<05:35,  7.29s/it]Generating:  71%|███████▏  | 112/157 [15:20<05:17,  7.07s/it]Generating:  72%|███████▏  | 113/157 [15:28<05:20,  7.28s/it]Generating:  73%|███████▎  | 114/157 [15:33<04:44,  6.61s/it]Generating:  73%|███████▎  | 115/157 [15:41<05:00,  7.15s/it]Generating:  74%|███████▍  | 116/157 [15:49<05:00,  7.32s/it]Generating:  75%|███████▍  | 117/157 [15:55<04:40,  7.00s/it]Generating:  75%|███████▌  | 118/157 [16:02<04:29,  6.91s/it]Generating:  76%|███████▌  | 119/157 [16:08<04:19,  6.83s/it]Generating:  76%|███████▋  | 120/157 [16:16<04:23,  7.13s/it]Generating:  77%|███████▋  | 121/157 [16:26<04:48,  8.03s/it]Generating:  78%|███████▊  | 122/157 [16:33<04:23,  7.53s/it]Generating:  78%|███████▊  | 123/157 [16:38<03:53,  6.85s/it]Generating:  79%|███████▉  | 124/157 [16:43<03:22,  6.14s/it]Generating:  80%|███████▉  | 125/157 [16:51<03:37,  6.80s/it]Generating:  80%|████████  | 126/157 [16:59<03:42,  7.17s/it]Generating:  81%|████████  | 127/157 [17:05<03:29,  6.97s/it]Generating:  82%|████████▏ | 128/157 [17:12<03:16,  6.78s/it]Generating:  82%|████████▏ | 129/157 [17:18<03:09,  6.77s/it]Generating:  83%|████████▎ | 130/157 [17:25<02:59,  6.65s/it]Generating:  83%|████████▎ | 131/157 [17:30<02:42,  6.26s/it]Generating:  84%|████████▍ | 132/157 [17:36<02:31,  6.07s/it]Generating:  85%|████████▍ | 133/157 [17:43<02:30,  6.27s/it]Generating:  85%|████████▌ | 134/157 [17:52<02:46,  7.25s/it]Generating:  86%|████████▌ | 135/157 [17:59<02:37,  7.17s/it]Generating:  87%|████████▋ | 136/157 [18:05<02:25,  6.94s/it]Generating:  87%|████████▋ | 137/157 [18:12<02:14,  6.74s/it]Generating:  88%|████████▊ | 138/157 [18:19<02:08,  6.76s/it]Generating:  89%|████████▊ | 139/157 [18:25<01:59,  6.64s/it]Generating:  89%|████████▉ | 140/157 [18:31<01:51,  6.56s/it]Generating:  90%|████████▉ | 141/157 [18:38<01:43,  6.48s/it]Generating:  90%|█████████ | 142/157 [18:46<01:44,  6.95s/it]Generating:  91%|█████████ | 143/157 [18:55<01:49,  7.79s/it]Generating:  92%|█████████▏| 144/157 [19:02<01:36,  7.39s/it]Generating:  92%|█████████▏| 145/157 [19:08<01:25,  7.15s/it]Generating:  93%|█████████▎| 146/157 [19:17<01:22,  7.48s/it]Generating:  94%|█████████▎| 147/157 [19:24<01:14,  7.50s/it]Generating:  94%|█████████▍| 148/157 [19:31<01:05,  7.26s/it]Generating:  95%|█████████▍| 149/157 [19:55<01:38, 12.35s/it]Generating:  96%|█████████▌| 150/157 [20:07<01:24, 12.07s/it]Generating:  96%|█████████▌| 151/157 [20:13<01:03, 10.50s/it]Generating:  97%|█████████▋| 152/157 [20:23<00:51, 10.34s/it]Generating:  97%|█████████▋| 153/157 [20:33<00:40, 10.17s/it]Generating:  98%|█████████▊| 154/157 [20:43<00:30, 10.01s/it]Generating:  99%|█████████▊| 155/157 [20:54<00:20, 10.30s/it]Generating:  99%|█████████▉| 156/157 [21:02<00:09,  9.75s/it]Generating: 100%|██████████| 157/157 [21:04<00:00,  7.38s/it]Generating: 100%|██████████| 157/157 [21:04<00:00,  8.05s/it]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 2740.30it/s]
Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`
Encoder model frozen.
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 1_base_evaluation.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
++ date
+ echo 'Done at: Sat Nov 29 13:15:44 CET 2025'
