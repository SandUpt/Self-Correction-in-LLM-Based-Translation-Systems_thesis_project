`torch_dtype` is deprecated! Use `dtype` instead!
We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|                                                                                           | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███████████████████████████▋                                                       | 1/3 [00:05<00:11,  5.95s/it]Loading checkpoint shards:  67%|███████████████████████████████████████████████████████▎                           | 2/3 [00:14<00:07,  7.34s/it]Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [00:19<00:00,  6.32s/it]Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [00:19<00:00,  6.45s/it]
Generating:   0%|                                                                                                         | 0/16 [00:00<?, ?it/s]Generating:   6%|██████                                                                                           | 1/16 [00:33<08:23, 33.56s/it]Generating:  12%|████████████▏                                                                                    | 2/16 [01:05<07:37, 32.66s/it]Generating:  19%|██████████████████▏                                                                              | 3/16 [01:36<06:57, 32.08s/it]Generating:  25%|████████████████████████▎                                                                        | 4/16 [02:09<06:28, 32.39s/it]Generating:  31%|██████████████████████████████▎                                                                  | 5/16 [02:39<05:46, 31.49s/it]Generating:  38%|████████████████████████████████████▍                                                            | 6/16 [03:10<05:12, 31.23s/it]Generating:  44%|██████████████████████████████████████████▍                                                      | 7/16 [03:40<04:38, 30.94s/it]Generating:  50%|████████████████████████████████████████████████▌                                                | 8/16 [04:11<04:05, 30.73s/it]Generating:  56%|██████████████████████████████████████████████████████▌                                          | 9/16 [04:43<03:38, 31.15s/it]Generating:  62%|████████████████████████████████████████████████████████████                                    | 10/16 [05:12<03:04, 30.69s/it]Generating:  69%|██████████████████████████████████████████████████████████████████                              | 11/16 [05:42<02:32, 30.49s/it]Generating:  75%|████████████████████████████████████████████████████████████████████████                        | 12/16 [06:14<02:03, 30.82s/it]Generating:  81%|██████████████████████████████████████████████████████████████████████████████                  | 13/16 [06:45<01:32, 30.92s/it]Generating:  88%|████████████████████████████████████████████████████████████████████████████████████            | 14/16 [07:19<01:03, 31.90s/it]Generating:  94%|██████████████████████████████████████████████████████████████████████████████████████████      | 15/16 [07:52<00:32, 32.10s/it]Generating: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [08:13<00:00, 28.88s/it]Generating: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [08:13<00:00, 30.86s/it]
Fetching 5 files:   0%|                                                                                                    | 0/5 [00:00<?, ?it/s]Fetching 5 files: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 23940.09it/s]
Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`
Encoder model frozen.
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 4_wmt_evaluation.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
