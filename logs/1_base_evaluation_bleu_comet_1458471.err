+ echo 'Job ID: 1458471'
+ echo 'Job Name: 1_base_evaluation_bleu_comet'
+ echo 'Node: gx02'
++ date
+ echo 'Start Time: Sun Nov 30 18:27:44 CET 2025'
++ pwd
+ echo 'Working Directory: /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/sh_files'
+ nvidia-smi
+ cd /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/scripts/
+ export TOKENIZERS_PARALLELISM=false
+ TOKENIZERS_PARALLELISM=false
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ echo 1_base_evaluation_bleu_comet
+ python3 1_base_evaluation_bleu_comet.py
`torch_dtype` is deprecated! Use `dtype` instead!
We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
Generating:   0%|          | 0/105 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Generating:   1%|          | 1/105 [01:26<2:30:06, 86.60s/it]Generating:   2%|▏         | 2/105 [02:49<2:25:20, 84.66s/it]Generating:   3%|▎         | 3/105 [04:16<2:25:16, 85.46s/it]Generating:   4%|▍         | 4/105 [05:39<2:22:16, 84.52s/it]Generating:   5%|▍         | 5/105 [07:03<2:20:33, 84.34s/it]Generating:   6%|▌         | 6/105 [08:23<2:16:57, 83.01s/it]Generating:   7%|▋         | 7/105 [09:43<2:13:44, 81.89s/it]Generating:   8%|▊         | 8/105 [11:00<2:09:42, 80.24s/it]Generating:   9%|▊         | 9/105 [12:27<2:11:47, 82.37s/it]Generating:  10%|▉         | 10/105 [13:53<2:12:28, 83.67s/it]Generating:  10%|█         | 11/105 [15:17<2:11:12, 83.75s/it]Generating:  11%|█▏        | 12/105 [16:40<2:09:27, 83.53s/it]Generating:  12%|█▏        | 13/105 [18:04<2:07:59, 83.47s/it]Generating:  13%|█▎        | 14/105 [19:33<2:09:12, 85.20s/it]Generating:  14%|█▍        | 15/105 [21:06<2:11:22, 87.58s/it]Generating:  15%|█▌        | 16/105 [22:26<2:06:45, 85.46s/it]Generating:  16%|█▌        | 17/105 [23:46<2:02:48, 83.73s/it]Generating:  17%|█▋        | 18/105 [25:14<2:03:14, 85.00s/it]Generating:  18%|█▊        | 19/105 [26:45<2:04:34, 86.92s/it]Generating:  19%|█▉        | 20/105 [28:07<2:00:44, 85.23s/it]Generating:  20%|██        | 21/105 [29:25<1:56:34, 83.26s/it]Generating:  21%|██        | 22/105 [30:47<1:54:29, 82.77s/it]Generating:  22%|██▏       | 23/105 [32:13<1:54:33, 83.82s/it]Generating:  23%|██▎       | 24/105 [33:37<1:53:08, 83.81s/it]Generating:  24%|██▍       | 25/105 [35:10<1:55:35, 86.70s/it]Generating:  25%|██▍       | 26/105 [36:36<1:53:40, 86.34s/it]Generating:  26%|██▌       | 27/105 [37:59<1:50:51, 85.28s/it]Generating:  27%|██▋       | 28/105 [39:18<1:47:13, 83.55s/it]Generating:  28%|██▊       | 29/105 [40:44<1:46:33, 84.12s/it]Generating:  29%|██▊       | 30/105 [42:02<1:43:05, 82.47s/it]Generating:  30%|██▉       | 31/105 [43:20<1:39:54, 81.00s/it]Generating:  30%|███       | 32/105 [44:42<1:38:47, 81.20s/it]Generating:  31%|███▏      | 33/105 [45:59<1:36:13, 80.19s/it]Generating:  32%|███▏      | 34/105 [47:20<1:35:00, 80.29s/it]Generating:  33%|███▎      | 35/105 [48:41<1:33:48, 80.41s/it]Generating:  34%|███▍      | 36/105 [50:06<1:34:07, 81.85s/it]Generating:  35%|███▌      | 37/105 [51:25<1:31:55, 81.11s/it]Generating:  36%|███▌      | 38/105 [52:43<1:29:20, 80.00s/it]Generating:  37%|███▋      | 39/105 [54:07<1:29:25, 81.30s/it]Generating:  38%|███▊      | 40/105 [55:28<1:28:06, 81.33s/it]Generating:  39%|███▉      | 41/105 [56:48<1:26:06, 80.73s/it]Generating:  40%|████      | 42/105 [58:11<1:25:34, 81.50s/it]Generating:  41%|████      | 43/105 [59:34<1:24:37, 81.89s/it]Generating:  42%|████▏     | 44/105 [1:00:54<1:22:50, 81.49s/it]Generating:  43%|████▎     | 45/105 [1:02:17<1:21:56, 81.93s/it]Generating:  44%|████▍     | 46/105 [1:03:39<1:20:30, 81.87s/it]Generating:  45%|████▍     | 47/105 [1:05:02<1:19:33, 82.30s/it]Generating:  46%|████▌     | 48/105 [1:06:28<1:18:59, 83.15s/it]Generating:  47%|████▋     | 49/105 [1:07:45<1:16:03, 81.50s/it]Generating:  48%|████▊     | 50/105 [1:09:07<1:14:44, 81.54s/it]Generating:  49%|████▊     | 51/105 [1:10:27<1:12:54, 81.00s/it]Generating:  50%|████▉     | 52/105 [1:11:56<1:13:53, 83.64s/it]Generating:  50%|█████     | 53/105 [1:13:23<1:13:09, 84.42s/it]Generating:  51%|█████▏    | 54/105 [1:14:57<1:14:15, 87.35s/it]Generating:  52%|█████▏    | 55/105 [1:16:22<1:12:22, 86.85s/it]Generating:  53%|█████▎    | 56/105 [1:17:45<1:09:59, 85.70s/it]Generating:  54%|█████▍    | 57/105 [1:19:07<1:07:36, 84.50s/it]Generating:  55%|█████▌    | 58/105 [1:20:29<1:05:27, 83.57s/it]Generating:  56%|█████▌    | 59/105 [1:21:52<1:04:07, 83.65s/it]Generating:  57%|█████▋    | 60/105 [1:23:20<1:03:37, 84.83s/it]Generating:  58%|█████▊    | 61/105 [1:24:43<1:01:44, 84.18s/it]Generating:  59%|█████▉    | 62/105 [1:26:04<59:37, 83.21s/it]  Generating:  60%|██████    | 63/105 [1:27:30<59:00, 84.30s/it]Generating:  61%|██████    | 64/105 [1:28:51<56:49, 83.16s/it]Generating:  62%|██████▏   | 65/105 [1:30:16<55:45, 83.63s/it]Generating:  63%|██████▎   | 66/105 [1:31:46<55:39, 85.63s/it]Generating:  64%|██████▍   | 67/105 [1:33:06<53:05, 83.82s/it]Generating:  65%|██████▍   | 68/105 [1:34:30<51:47, 83.99s/it]Generating:  66%|██████▌   | 69/105 [1:35:49<49:27, 82.42s/it]Generating:  67%|██████▋   | 70/105 [1:37:18<49:15, 84.43s/it]Generating:  68%|██████▊   | 71/105 [1:38:43<47:55, 84.57s/it]Generating:  69%|██████▊   | 72/105 [1:40:07<46:24, 84.38s/it]Generating:  70%|██████▉   | 73/105 [1:41:27<44:25, 83.29s/it]Generating:  70%|███████   | 74/105 [1:42:55<43:37, 84.44s/it]Generating:  71%|███████▏  | 75/105 [1:44:16<41:43, 83.44s/it]Generating:  72%|███████▏  | 76/105 [1:45:34<39:36, 81.93s/it]Generating:  73%|███████▎  | 77/105 [1:47:00<38:43, 83.00s/it]Generating:  74%|███████▍  | 78/105 [1:48:22<37:19, 82.94s/it]Generating:  75%|███████▌  | 79/105 [1:49:45<35:51, 82.74s/it]Generating:  76%|███████▌  | 80/105 [1:51:05<34:10, 82.03s/it]Generating:  77%|███████▋  | 81/105 [1:52:30<33:09, 82.91s/it]Generating:  78%|███████▊  | 82/105 [1:53:53<31:45, 82.86s/it]Generating:  79%|███████▉  | 83/105 [1:55:14<30:15, 82.52s/it]Generating:  80%|████████  | 84/105 [1:56:37<28:56, 82.67s/it]Generating:  81%|████████  | 85/105 [1:58:05<28:03, 84.18s/it]Generating:  82%|████████▏ | 86/105 [1:59:30<26:44, 84.42s/it]Generating:  83%|████████▎ | 87/105 [2:00:54<25:16, 84.28s/it]Generating:  84%|████████▍ | 88/105 [2:02:20<23:58, 84.65s/it]Generating:  85%|████████▍ | 89/105 [2:03:42<22:25, 84.09s/it]Generating:  86%|████████▌ | 90/105 [2:05:01<20:38, 82.54s/it]Generating:  87%|████████▋ | 91/105 [2:06:24<19:15, 82.53s/it]Generating:  88%|████████▊ | 92/105 [2:07:47<17:54, 82.66s/it]Generating:  89%|████████▊ | 93/105 [2:09:10<16:34, 82.88s/it]Generating:  90%|████████▉ | 94/105 [2:10:29<14:57, 81.61s/it]Generating:  90%|█████████ | 95/105 [2:11:53<13:45, 82.53s/it]Generating:  91%|█████████▏| 96/105 [2:13:18<12:29, 83.23s/it]Generating:  92%|█████████▏| 97/105 [2:14:40<11:02, 82.76s/it]Generating:  93%|█████████▎| 98/105 [2:16:02<09:38, 82.66s/it]Generating:  94%|█████████▍| 99/105 [2:17:25<08:16, 82.76s/it]Generating:  95%|█████████▌| 100/105 [2:18:50<06:55, 83.17s/it]Generating:  96%|█████████▌| 101/105 [2:20:09<05:28, 82.11s/it]Generating:  97%|█████████▋| 102/105 [2:21:32<04:06, 82.31s/it]Generating:  98%|█████████▊| 103/105 [2:23:01<02:48, 84.31s/it]Generating:  99%|█████████▉| 104/105 [2:24:23<01:23, 83.65s/it]Generating: 100%|██████████| 105/105 [2:24:40<00:00, 63.65s/it]Generating: 100%|██████████| 105/105 [2:24:40<00:00, 82.67s/it]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 1645.08it/s]
Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`
Encoder model frozen.
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 1_base_evaluation_bleu_comet.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 1_base_evaluation_bleu_comet.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
++ date
+ echo 'Done at: Sun Nov 30 20:55:20 CET 2025'
