`torch_dtype` is deprecated! Use `dtype` instead!
We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|                                                         | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|████████████▎                                    | 1/4 [00:00<00:01,  1.61it/s]Loading checkpoint shards:  50%|████████████████████████▌                        | 2/4 [00:01<00:01,  1.67it/s]Loading checkpoint shards:  75%|████████████████████████████████████▊            | 3/4 [00:01<00:00,  1.65it/s]Loading checkpoint shards: 100%|█████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.73it/s]Loading checkpoint shards: 100%|█████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.70it/s]
Generating:   0%|                                                                       | 0/11 [00:00<?, ?it/s]Generating:   9%|█████▋                                                         | 1/11 [00:28<04:42, 28.22s/it]Generating:  18%|███████████▍                                                   | 2/11 [00:55<04:10, 27.86s/it]Generating:  27%|█████████████████▏                                             | 3/11 [01:24<03:44, 28.05s/it]Generating:  36%|██████████████████████▉                                        | 4/11 [01:51<03:13, 27.64s/it]Generating:  45%|████████████████████████████▋                                  | 5/11 [02:18<02:45, 27.63s/it]Generating:  55%|██████████████████████████████████▎                            | 6/11 [02:46<02:18, 27.64s/it]Generating:  64%|████████████████████████████████████████                       | 7/11 [03:13<01:49, 27.45s/it]Generating:  73%|█████████████████████████████████████████████▊                 | 8/11 [03:41<01:23, 27.78s/it]Generating:  82%|███████████████████████████████████████████████████▌           | 9/11 [04:09<00:55, 27.63s/it]Generating:  91%|████████████████████████████████████████████████████████▎     | 10/11 [04:37<00:27, 27.91s/it]Generating: 100%|██████████████████████████████████████████████████████████████| 11/11 [04:45<00:00, 21.60s/it]Generating: 100%|██████████████████████████████████████████████████████████████| 11/11 [04:45<00:00, 25.92s/it]
Fetching 5 files:   0%|                                                                  | 0/5 [00:00<?, ?it/s]Fetching 5 files: 100%|████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 1483.03it/s]
Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`
Encoder model frozen.
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 1_base_evaluation.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
