+ echo 'Job ID: 1457975'
+ echo 'Job Name: 11_sc_direct_evluation_2'
+ echo 'Node: gx02'
++ date
+ echo 'Start Time: Sun Nov 30 10:00:59 CET 2025'
++ pwd
+ echo 'Working Directory: /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/sh_files'
+ nvidia-smi
+ cd /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/scripts/
+ export TOKENIZERS_PARALLELISM=false
+ TOKENIZERS_PARALLELISM=false
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ echo 11_sc_direct_evluation_2
+ python3 11_sc_direct_evluation_2.py
`torch_dtype` is deprecated! Use `dtype` instead!
We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:09<00:18,  9.28s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:18<00:09,  9.40s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:25<00:00,  8.37s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:25<00:00,  8.63s/it]
Generating:   0%|          | 0/157 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Generating:   1%|          | 1/157 [01:28<3:51:10, 88.91s/it]Generating:   1%|▏         | 2/157 [02:55<3:45:36, 87.33s/it]Generating:   2%|▏         | 3/157 [04:23<3:45:00, 87.66s/it]Generating:   3%|▎         | 4/157 [05:49<3:42:12, 87.14s/it]Generating:   3%|▎         | 5/157 [07:17<3:41:30, 87.43s/it]Generating:   4%|▍         | 6/157 [08:44<3:39:25, 87.19s/it]Generating:   4%|▍         | 7/157 [10:13<3:39:51, 87.94s/it]Generating:   5%|▌         | 8/157 [11:41<3:38:16, 87.90s/it]Generating:   6%|▌         | 9/157 [13:09<3:36:57, 87.96s/it]Generating:   6%|▋         | 10/157 [14:39<3:37:13, 88.66s/it]Generating:   7%|▋         | 11/157 [16:31<3:52:59, 95.75s/it]Generating:   8%|▊         | 12/157 [18:15<3:57:02, 98.08s/it]Generating:   8%|▊         | 13/157 [19:59<4:00:21, 100.15s/it]Generating:   9%|▉         | 14/157 [21:54<4:09:02, 104.49s/it]Generating:  10%|▉         | 15/157 [23:50<4:15:38, 108.02s/it]Generating:  10%|█         | 16/157 [26:03<4:31:08, 115.38s/it]Generating:  11%|█         | 17/157 [27:40<4:16:35, 109.97s/it]Generating:  11%|█▏        | 18/157 [29:08<3:59:18, 103.30s/it]Generating:  12%|█▏        | 19/157 [30:38<3:48:33, 99.37s/it] Generating:  13%|█▎        | 20/157 [32:07<3:39:37, 96.18s/it]Generating:  13%|█▎        | 21/157 [33:37<3:33:48, 94.33s/it]Generating:  14%|█▍        | 22/157 [35:06<3:29:04, 92.92s/it]Generating:  15%|█▍        | 23/157 [36:39<3:27:33, 92.94s/it]Generating:  15%|█▌        | 24/157 [38:08<3:23:17, 91.71s/it]Generating:  16%|█▌        | 25/157 [39:39<3:21:19, 91.51s/it]Generating:  17%|█▋        | 26/157 [41:06<3:16:34, 90.04s/it]Generating:  17%|█▋        | 27/157 [42:38<3:16:32, 90.71s/it]Generating:  18%|█▊        | 28/157 [44:05<3:12:46, 89.66s/it]Generating:  18%|█▊        | 29/157 [45:32<3:09:32, 88.85s/it]Generating:  19%|█▉        | 30/157 [47:04<3:09:46, 89.66s/it]Generating:  20%|█▉        | 31/157 [48:29<3:05:42, 88.43s/it]Generating:  20%|██        | 32/157 [49:57<3:03:46, 88.21s/it]Generating:  21%|██        | 33/157 [51:25<3:01:59, 88.06s/it]Generating:  22%|██▏       | 34/157 [52:55<3:01:38, 88.61s/it]Generating:  22%|██▏       | 35/157 [54:26<3:01:32, 89.29s/it]Generating:  23%|██▎       | 36/157 [55:55<3:00:24, 89.46s/it]Generating:  24%|██▎       | 37/157 [57:22<2:57:20, 88.67s/it]Generating:  24%|██▍       | 38/157 [58:48<2:54:00, 87.73s/it]Generating:  25%|██▍       | 39/157 [1:00:13<2:50:45, 86.83s/it]Generating:  25%|██▌       | 40/157 [1:01:42<2:50:42, 87.54s/it]Generating:  26%|██▌       | 41/157 [1:03:15<2:52:22, 89.16s/it]Generating:  27%|██▋       | 42/157 [1:04:39<2:48:20, 87.83s/it]Generating:  27%|██▋       | 43/157 [1:06:08<2:47:07, 87.96s/it]Generating:  28%|██▊       | 44/157 [1:07:37<2:46:27, 88.39s/it]Generating:  29%|██▊       | 45/157 [1:09:06<2:45:31, 88.68s/it]Generating:  29%|██▉       | 46/157 [1:10:37<2:45:02, 89.21s/it]Generating:  30%|██▉       | 47/157 [1:12:04<2:42:07, 88.43s/it]Generating:  31%|███       | 48/157 [1:13:34<2:41:55, 89.13s/it]Generating:  31%|███       | 49/157 [1:15:05<2:41:10, 89.54s/it]Generating:  32%|███▏      | 50/157 [1:16:36<2:40:37, 90.07s/it]Generating:  32%|███▏      | 51/157 [1:18:05<2:38:45, 89.86s/it]Generating:  33%|███▎      | 52/157 [1:19:31<2:34:48, 88.46s/it]Generating:  34%|███▍      | 53/157 [1:20:58<2:32:54, 88.22s/it]Generating:  34%|███▍      | 54/157 [1:22:36<2:36:23, 91.10s/it]Generating:  35%|███▌      | 55/157 [1:24:03<2:32:28, 89.69s/it]Generating:  36%|███▌      | 56/157 [1:25:36<2:32:54, 90.84s/it]Generating:  36%|███▋      | 57/157 [1:27:05<2:30:40, 90.41s/it]Generating:  37%|███▋      | 58/157 [1:28:34<2:28:06, 89.76s/it]Generating:  38%|███▊      | 59/157 [1:30:02<2:26:05, 89.44s/it]Generating:  38%|███▊      | 60/157 [1:31:28<2:22:40, 88.25s/it]Generating:  39%|███▉      | 61/157 [1:32:57<2:21:48, 88.63s/it]Generating:  39%|███▉      | 62/157 [1:34:26<2:20:30, 88.74s/it]Generating:  40%|████      | 63/157 [1:35:56<2:19:20, 88.94s/it]Generating:  41%|████      | 64/157 [1:37:26<2:18:17, 89.22s/it]Generating:  41%|████▏     | 65/157 [1:38:57<2:17:53, 89.93s/it]Generating:  42%|████▏     | 66/157 [1:40:25<2:15:18, 89.21s/it]Generating:  43%|████▎     | 67/157 [1:41:54<2:13:57, 89.31s/it]Generating:  43%|████▎     | 68/157 [1:43:24<2:12:34, 89.38s/it]Generating:  44%|████▍     | 69/157 [1:44:51<2:10:16, 88.82s/it]Generating:  45%|████▍     | 70/157 [1:46:20<2:08:32, 88.65s/it]Generating:  45%|████▌     | 71/157 [1:47:51<2:08:06, 89.38s/it]Generating:  46%|████▌     | 72/157 [1:49:19<2:06:14, 89.11s/it]Generating:  46%|████▋     | 73/157 [1:50:50<2:05:28, 89.62s/it]Generating:  47%|████▋     | 74/157 [1:52:18<2:03:12, 89.06s/it]Generating:  48%|████▊     | 75/157 [1:53:47<2:01:53, 89.19s/it]Generating:  48%|████▊     | 76/157 [1:55:16<2:00:23, 89.18s/it]Generating:  49%|████▉     | 77/157 [1:56:43<1:57:42, 88.28s/it]Generating:  50%|████▉     | 78/157 [1:58:12<1:56:30, 88.49s/it]Generating:  50%|█████     | 79/157 [1:59:39<1:54:44, 88.26s/it]Generating:  51%|█████     | 80/157 [2:01:06<1:52:50, 87.93s/it]Generating:  52%|█████▏    | 81/157 [2:02:34<1:51:11, 87.78s/it]Generating:  52%|█████▏    | 82/157 [2:04:04<1:50:35, 88.47s/it]Generating:  53%|█████▎    | 83/157 [2:05:33<1:49:25, 88.73s/it]Generating:  54%|█████▎    | 84/157 [2:07:05<1:49:11, 89.74s/it]Generating:  54%|█████▍    | 85/157 [2:08:36<1:48:09, 90.13s/it]Generating:  55%|█████▍    | 86/157 [2:10:02<1:45:11, 88.89s/it]Generating:  55%|█████▌    | 87/157 [2:11:35<1:44:51, 89.87s/it]Generating:  56%|█████▌    | 88/157 [2:13:01<1:42:01, 88.72s/it]Generating:  57%|█████▋    | 89/157 [2:14:27<1:39:46, 88.03s/it]Generating:  57%|█████▋    | 90/157 [2:15:55<1:38:16, 88.00s/it]Generating:  58%|█████▊    | 91/157 [2:17:29<1:38:54, 89.91s/it]Generating:  59%|█████▊    | 92/157 [2:18:57<1:36:41, 89.25s/it]Generating:  59%|█████▉    | 93/157 [2:20:21<1:33:33, 87.72s/it]Generating:  60%|█████▉    | 94/157 [2:21:52<1:32:58, 88.54s/it]Generating:  61%|██████    | 95/157 [2:23:21<1:31:40, 88.71s/it]Generating:  61%|██████    | 96/157 [2:24:50<1:30:11, 88.71s/it]Generating:  62%|██████▏   | 97/157 [2:26:16<1:28:10, 88.18s/it]Generating:  62%|██████▏   | 98/157 [2:27:45<1:26:54, 88.38s/it]Generating:  63%|██████▎   | 99/157 [2:29:11<1:24:44, 87.67s/it]Generating:  64%|██████▎   | 100/157 [2:30:42<1:24:00, 88.43s/it]Generating:  64%|██████▍   | 101/157 [2:32:07<1:21:34, 87.41s/it]Generating:  65%|██████▍   | 102/157 [2:33:32<1:19:42, 86.96s/it]Generating:  66%|██████▌   | 103/157 [2:35:03<1:19:12, 88.00s/it]Generating:  66%|██████▌   | 104/157 [2:36:33<1:18:23, 88.74s/it]Generating:  67%|██████▋   | 105/157 [2:38:01<1:16:34, 88.35s/it]Generating:  68%|██████▊   | 106/157 [2:39:29<1:15:09, 88.42s/it]Generating:  68%|██████▊   | 107/157 [2:40:57<1:13:28, 88.17s/it]Generating:  69%|██████▉   | 108/157 [2:42:27<1:12:21, 88.61s/it]Generating:  69%|██████▉   | 109/157 [2:43:55<1:10:43, 88.41s/it]Generating:  70%|███████   | 110/157 [2:45:22<1:09:00, 88.11s/it]Generating:  71%|███████   | 111/157 [2:46:51<1:07:51, 88.52s/it]Generating:  71%|███████▏  | 112/157 [2:48:20<1:06:20, 88.45s/it]Generating:  72%|███████▏  | 113/157 [2:49:45<1:04:14, 87.61s/it]Generating:  73%|███████▎  | 114/157 [2:51:12<1:02:30, 87.21s/it]Generating:  73%|███████▎  | 115/157 [2:52:42<1:01:36, 88.01s/it]Generating:  74%|███████▍  | 116/157 [2:54:09<59:58, 87.76s/it]  Generating:  75%|███████▍  | 117/157 [2:55:37<58:40, 88.00s/it]Generating:  75%|███████▌  | 118/157 [2:57:06<57:17, 88.13s/it]Generating:  76%|███████▌  | 119/157 [2:58:35<56:01, 88.46s/it]Generating:  76%|███████▋  | 120/157 [3:00:02<54:16, 88.00s/it]Generating:  77%|███████▋  | 121/157 [3:01:32<53:06, 88.53s/it]Generating:  78%|███████▊  | 122/157 [3:03:01<51:43, 88.67s/it]Generating:  78%|███████▊  | 123/157 [3:04:26<49:39, 87.64s/it]Generating:  79%|███████▉  | 124/157 [3:05:50<47:34, 86.49s/it]Generating:  80%|███████▉  | 125/157 [3:07:17<46:15, 86.73s/it]Generating:  80%|████████  | 126/157 [3:08:45<45:04, 87.25s/it]Generating:  81%|████████  | 127/157 [3:10:15<43:59, 87.97s/it]Generating:  82%|████████▏ | 128/157 [3:11:42<42:18, 87.54s/it]Generating:  82%|████████▏ | 129/157 [3:13:07<40:29, 86.78s/it]Generating:  83%|████████▎ | 130/157 [3:14:31<38:45, 86.14s/it]Generating:  83%|████████▎ | 131/157 [3:16:01<37:48, 87.24s/it]Generating:  84%|████████▍ | 132/157 [3:17:26<36:04, 86.60s/it]Generating:  85%|████████▍ | 133/157 [3:18:53<34:40, 86.69s/it]Generating:  85%|████████▌ | 134/157 [3:20:24<33:45, 88.06s/it]Generating:  86%|████████▌ | 135/157 [3:21:51<32:07, 87.62s/it]Generating:  87%|████████▋ | 136/157 [3:23:23<31:06, 88.89s/it]Generating:  87%|████████▋ | 137/157 [3:24:51<29:35, 88.78s/it]Generating:  88%|████████▊ | 138/157 [3:26:19<27:59, 88.42s/it]Generating:  89%|████████▊ | 139/157 [3:27:44<26:14, 87.47s/it]Generating:  89%|████████▉ | 140/157 [3:29:12<24:50, 87.71s/it]Generating:  90%|████████▉ | 141/157 [3:30:42<23:31, 88.22s/it]Generating:  90%|█████████ | 142/157 [3:32:11<22:08, 88.57s/it]Generating:  91%|█████████ | 143/157 [3:33:39<20:37, 88.43s/it]Generating:  92%|█████████▏| 144/157 [3:35:09<19:14, 88.78s/it]Generating:  92%|█████████▏| 145/157 [3:36:37<17:44, 88.71s/it]Generating:  93%|█████████▎| 146/157 [3:38:06<16:15, 88.66s/it]Generating:  94%|█████████▎| 147/157 [3:39:34<14:46, 88.62s/it]Generating:  94%|█████████▍| 148/157 [3:41:03<13:18, 88.67s/it]Generating:  95%|█████████▍| 149/157 [3:42:33<11:52, 89.04s/it]Generating:  96%|█████████▌| 150/157 [3:43:58<10:15, 87.91s/it]Generating:  96%|█████████▌| 151/157 [3:45:29<08:51, 88.57s/it]Generating:  97%|█████████▋| 152/157 [3:46:58<07:24, 88.82s/it]Generating:  97%|█████████▋| 153/157 [3:48:22<05:49, 87.37s/it]Generating:  98%|█████████▊| 154/157 [3:49:52<04:24, 88.25s/it]Generating:  99%|█████████▊| 155/157 [3:51:25<02:58, 89.49s/it]Generating:  99%|█████████▉| 156/157 [3:52:52<01:28, 88.77s/it]Generating: 100%|██████████| 157/157 [3:53:19<00:00, 70.19s/it]Generating: 100%|██████████| 157/157 [3:53:19<00:00, 89.17s/it]
Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 1533.12it/s]
Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`
Encoder model frozen.
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 11_sc_direct_evluation_2.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 11_sc_direct_evluation_2.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 11_sc_direct_evluation_2.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/sc/home/sandeep.uprety/.local/lib/python3.12/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 11_sc_direct_evluation_2.py ...
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
++ date
+ echo 'Done at: Sun Nov 30 13:58:10 CET 2025'
