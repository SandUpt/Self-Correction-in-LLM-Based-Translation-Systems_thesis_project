Using GPU inside JupyterLab session
stdout log: ../logs/3_wmt_merge.py_20251129_124341.log
stderr log: ../logs/3_wmt_merge.py_20251129_124341.err
Start Time: Sat Nov 29 12:43:41 CET 2025
Node: gx27
Working Directory: /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/sh_files
Sat Nov 29 12:43:41 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A40                     Off |   00000000:81:00.0 Off |                    0 |
|  0%   59C    P0            129W /  300W |     877MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A         1277245      C   /usr/bin/python3                        868MiB |
+-----------------------------------------------------------------------------------------+
============================================================
Merging LoRA Adapter
Model: qwen
Language Pair: zh_en
============================================================

Loading base model: Qwen/Qwen2.5-7B-Instruct
Loading tokenizer
Loading adapter from: ../models/wmt_adapters/qwen_zh_en
Merging adapter weights
Saving merged model to: ../models/wmt_merged/qwen_zh_en

Merge complete.
Merged model saved to: ../models/wmt_merged/qwen_zh_en
Done at: Sat Nov 29 12:44:41 CET 2025
