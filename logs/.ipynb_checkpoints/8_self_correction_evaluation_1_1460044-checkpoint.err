+ echo 'Job ID: 1460044'
+ echo 'Job Name: 8_self_correction_evaluation_1'
+ echo 'Node: gx25'
++ date
+ echo 'Start Time: Tue Dec  2 08:22:10 CET 2025'
++ pwd
+ echo 'Working Directory: /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/sh_files'
+ nvidia-smi
+ cd /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/scripts/
+ export TOKENIZERS_PARALLELISM=false
+ TOKENIZERS_PARALLELISM=false
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ echo 8_self_correction_evaluation_1
+ python3 8_self_correction_evaluation_1.py
`torch_dtype` is deprecated! Use `dtype` instead!
We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:13<00:26, 13.26s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:25<00:12, 12.38s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:35<00:00, 11.39s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:35<00:00, 11.75s/it]
Generating:   0%|          | 0/157 [00:00<?, ?it/s]Generating:   1%|          | 1/157 [00:55<2:24:21, 55.52s/it]Generating:   1%|▏         | 2/157 [01:50<2:23:13, 55.44s/it]Generating:   2%|▏         | 3/157 [02:43<2:19:01, 54.16s/it]Generating:   3%|▎         | 4/157 [03:40<2:20:51, 55.24s/it]Generating:   3%|▎         | 5/157 [04:32<2:17:24, 54.24s/it]Generating:   4%|▍         | 6/157 [05:26<2:16:12, 54.12s/it]Generating:   4%|▍         | 7/157 [06:17<2:12:46, 53.11s/it]Generating:   5%|▌         | 8/157 [07:11<2:12:22, 53.30s/it]Generating:   6%|▌         | 9/157 [08:05<2:11:40, 53.38s/it]Generating:   6%|▋         | 10/157 [08:57<2:09:55, 53.03s/it]Generating:   7%|▋         | 11/157 [09:50<2:09:04, 53.04s/it]Generating:   8%|▊         | 12/157 [10:43<2:08:01, 52.98s/it]Generating:   8%|▊         | 13/157 [11:39<2:09:36, 54.00s/it]Generating:   9%|▉         | 14/157 [12:34<2:09:33, 54.36s/it]Generating:  10%|▉         | 15/157 [13:31<2:10:15, 55.04s/it]Generating:  10%|█         | 16/157 [14:25<2:08:39, 54.75s/it]Generating:  11%|█         | 17/157 [15:22<2:09:08, 55.34s/it]Generating:  11%|█▏        | 18/157 [16:14<2:06:22, 54.55s/it]Generating:  12%|█▏        | 19/157 [17:10<2:05:56, 54.76s/it]Generating:  13%|█▎        | 20/157 [18:02<2:03:43, 54.19s/it]Generating:  13%|█▎        | 21/157 [19:00<2:05:12, 55.24s/it]Generating:  14%|█▍        | 22/157 [20:00<2:07:09, 56.52s/it]Generating:  15%|█▍        | 23/157 [20:52<2:03:43, 55.40s/it]Generating:  15%|█▌        | 24/157 [21:45<2:01:06, 54.63s/it]Generating:  16%|█▌        | 25/157 [22:39<1:59:34, 54.35s/it]Generating:  17%|█▋        | 26/157 [23:32<1:58:03, 54.07s/it]Generating:  17%|█▋        | 27/157 [24:28<1:57:53, 54.41s/it]Generating:  18%|█▊        | 28/157 [25:23<1:57:23, 54.60s/it]Generating:  18%|█▊        | 29/157 [26:21<1:58:48, 55.69s/it]Generating:  19%|█▉        | 30/157 [27:14<1:56:00, 54.80s/it]Generating:  20%|█▉        | 31/157 [28:07<1:53:51, 54.22s/it]Generating:  20%|██        | 32/157 [28:59<1:52:06, 53.81s/it]Generating:  21%|██        | 33/157 [29:55<1:52:06, 54.25s/it]Generating:  22%|██▏       | 34/157 [30:52<1:52:56, 55.10s/it]Generating:  22%|██▏       | 35/157 [31:44<1:50:23, 54.29s/it]Generating:  23%|██▎       | 36/157 [32:38<1:49:08, 54.12s/it]Generating:  24%|██▎       | 37/157 [33:31<1:47:23, 53.70s/it]