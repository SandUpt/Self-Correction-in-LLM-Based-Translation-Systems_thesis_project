+ echo 'Job ID: 1460013'
+ echo 'Job Name: 8_self_correction_evaluation_1'
+ echo 'Node: gx25'
++ date
+ echo 'Start Time: Tue Dec  2 08:05:07 CET 2025'
++ pwd
+ echo 'Working Directory: /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/sh_files'
+ nvidia-smi
+ cd /sc/home/sandeep.uprety/thesis_project/self_correction_llm_based_translation_thesis/thesis_project/scripts/
+ export TOKENIZERS_PARALLELISM=false
+ TOKENIZERS_PARALLELISM=false
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ echo 8_self_correction_evaluation_1
+ python3 8_self_correction_evaluation_1.py
`torch_dtype` is deprecated! Use `dtype` instead!
We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:10<00:31, 10.41s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:20<00:20, 10.40s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:29<00:09,  9.40s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:31<00:00,  6.65s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:31<00:00,  7.86s/it]
Generating:   0%|          | 0/157 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Generating:   1%|          | 1/157 [00:34<1:30:28, 34.80s/it]